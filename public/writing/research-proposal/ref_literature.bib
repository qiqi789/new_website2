@InProceedings{Boehmer2023,
  author    = {Boehmer, Niclas and Faliszewski, Piotr and Janeczko, {\L}ukasz and Kaczmarczyk, Andrzej},
  booktitle = {Algorithmic Game Theory},
  title     = {Robustness of Participatory Budgeting Outcomes: Complexity and Experiments},
  year      = {2023},
  address   = {Cham},
  editor    = {Deligkas, Argyrios and Filos-Ratsikas, Aris},
  pages     = {161--178},
  publisher = {Springer Nature Switzerland},
  abstract  = {We study the robustness of approval-based participatory budgeting (PB) rules to random noise in the votes. First, we analyze the computational complexity of the {\#}Flip-Bribery problem, where given a PB instance we ask for the number of ways in which we can flip a given number of approvals in the votes, so that a specific project is selected. This problem captures computing the funding probabilities of projects in case random noise is added. Unfortunately, it is intractable even for the simplest PB rules. Second, we analyze the robustness of several prominent PB rules (including the basic greedy rule and the Method of Equal Shares) on real-world instances from Pabulib. Using sampling, we quantify the extent to which simple, greedy PB rules are more robust than proportional ones, and we identify three types of (very) non-robust projects in real-world PB instances.},
  isbn      = {978-3-031-43254-5},
  priority  = {prio2},
  ranking   = {rank4},
}

@InProceedings{Aumann2010,
  author    = {Aumann, Yonatan and Dombb, Yair},
  booktitle = {Algorithmic Game Theory},
  title     = {Pareto Efficiency and Approximate Pareto Efficiency in Routing and Load Balancing Games},
  year      = {2010},
  address   = {Berlin, Heidelberg},
  editor    = {Kontogiannis, Spyros and Koutsoupias, Elias and Spirakis, Paul G.},
  pages     = {66--77},
  publisher = {Springer Berlin Heidelberg},
  abstract  = {We analyze the Pareto efficiency, or inefficiency, of solutions to routing games and load balancing games, focusing on Nash equilibria and greedy solutions to these games. For some settings, we show that the solutions are necessarily Pareto optimal. When this is not the case, we provide a measure to quantify the distance of the solution from Pareto efficiency. Using this measure, we provide upper and lower bounds on the ``Pareto inefficiency'' of the different solutions. The settings we consider include load balancing games on identical, uniformly-related, and unrelated machines, both using pure and mixed strategies, and nonatomic routing in general and some specific networks.},
  isbn      = {978-3-642-16170-4},
}

@InProceedings{Kobayashi2023,
  author    = {Kobayashi, Yusuke and Mahara, Ryoga and Sakamoto, Souta},
  booktitle = {Algorithmic Game Theory},
  title     = {EFX Allocations for Indivisible Chores: Matching-Based Approach},
  year      = {2023},
  address   = {Cham},
  editor    = {Deligkas, Argyrios and Filos-Ratsikas, Aris},
  pages     = {257--270},
  publisher = {Springer Nature Switzerland},
  abstract  = {One of the most important topics in discrete fair division is whether an EFX allocation exists for any instance. Although the existence of EFX allocations is a standing open problem for both goods and chores, the understanding of the existence of EFX allocations for chores is less established compared to goods. We study the existence of EFX allocation for chores under the assumption that all agent's cost functions are additive. Specifically, we show the existence of EFX allocations for the following three cases: (i) the number of chores is at most twice the number of agents, (ii) the cost functions of all agents except for one are identical ordering, and (iii) the number of agents is three and each agent has a personalized bi-valued cost function. Furthermore, we provide a polynomial time algorithm to find an EFX allocation for each case.},
  isbn      = {978-3-031-43254-5},
  ranking   = {rank4},
}

@InProceedings{Botan2023,
  author    = {Botan, Sirin and Ritossa, Angus and Suzuki, Mashbat and Walsh, Toby},
  booktitle = {Algorithmic Game Theory},
  title     = {Maximin Fair Allocation of Indivisible Items Under Cost Utilities},
  year      = {2023},
  address   = {Cham},
  editor    = {Deligkas, Argyrios and Filos-Ratsikas, Aris},
  pages     = {221--238},
  publisher = {Springer Nature Switzerland},
  abstract  = {We study the problem of fairly allocating indivisible goods among a set of agents. Our focus is on the existence of allocations that give each agent their maximin fair share---the value they are guaranteed if they divide the goods into as many bundles as there are agents, and receive their lowest valued bundle. An MMS allocation is one where every agent receives at least their maximin fair share. We examine the existence of such allocations when agents have cost utilities. In this setting, each item has an associated cost, and an agent's valuation for an item is the cost of the item if it is useful to them, and zero otherwise.},
  isbn      = {978-3-031-43254-5},
}

@InProceedings{Wagner2023,
  author    = {Wagner, Jonathan and Meir, Reshef},
  booktitle = {Algorithmic Game Theory},
  title     = {Strategy-Proof Budgeting via a VCG-Like Mechanism},
  year      = {2023},
  address   = {Cham},
  editor    = {Deligkas, Argyrios and Filos-Ratsikas, Aris},
  pages     = {401--418},
  publisher = {Springer Nature Switzerland},
  abstract  = {We present a strategy-proof public goods budgeting mechanism where agents determine both the total volume of expenses and specific allocation. It is constructed as a modification of VCG to a non-typical environment, where we do not assume quasi-linear utilities or direct revelation. We further show that under plausible assumptions it satisfies strategyproofness in strictly dominant strategies, and consequently implements the social optimum as a Coalition-Proof Nash Equilibrium. A primary (albeit not an exclusive) motivation of our model is Participatory Budgeting, where members of a community collectively decide the spending policy of public tax dollars. In that scenario, charging individual payments from voters as the VCG method instructs would be undesirable, thus our second main result provides that, under further specifications relevant in that context, these payments will vanish in large populations, and can further be constructed as non-positive in some cases.},
  isbn      = {978-3-031-43254-5},
  ranking   = {rank5},
}

@Article{Gao2021,
  author   = {Gao, Zijun and Hastie, Trevor and Tibshirani, Robert},
  journal  = {Statistics in Medicine},
  title    = {Assessment of heterogeneous treatment effect estimation accuracy via matching},
  year     = {2021},
  number   = {17},
  pages    = {3990-4013},
  volume   = {40},
  abstract = {We study the assessment of the accuracy of heterogeneous treatment effect (HTE) estimation, where the HTE is not directly observable so standard computation of prediction errors is not applicable. To tackle the difficulty, we propose an assessment approach by constructing pseudo-observations of the HTE based on matching. Our contributions are three-fold: first, we introduce a novel matching distance derived from proximity scores in random forests; second, we formulate the matching problem as an average minimum-cost flow problem and provide an efficient algorithm; third, we propose a match-then-split principle for the assessment with cross-validation. We demonstrate the efficacy of the assessment approach using simulations and a real dataset.},
  doi      = {https://doi.org/10.1002/sim.9010},
  eprint   = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/sim.9010},
  keywords = {heterogeneous treatment effect, matching, model assessment, proximity scores},
  ranking  = {rank4},
  url      = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.9010},
}






@Article{Rosenbaum2020,
  author   = {Rosenbaum, Paul R.},
  journal  = {Annual Review of Statistics and Its Application},
  title    = {Modern Algorithms for Matching in Observational Studies},
  year     = {2020},
  number   = {1},
  pages    = {143-176},
  volume   = {7},
  abstract = {Using a small example as an illustration, this article reviews multivariate matching from the perspective of a working scientist who wishes to make effective use of available methods. The several goals of multivariate matching are discussed. Matching tools are reviewed, including propensity scores, covariate distances, fine balance, and related methods such as near-fine and refined balance, exact and near-exact matching, tactics addressing missing covariate values, the entire number, and checks of covariate balance. Matching structures are described, such as matching with a variable number of controls, full matching, subset matching and risk-set matching. Software packages in R are described. A brief review is given of the theory underlying propensity scores and the associated sensitivity analysis concerning an unobserved covariate omitted from the propensity score.},
  doi      = {10.1146/annurev-statistics-031219-041058},
  eprint   = {https://doi.org/10.1146/annurev-statistics-031219-041058},
  ranking  = {rank5},
  url      = {https://doi.org/10.1146/annurev-statistics-031219-041058},
}

@Article{Silber2014,
  author   = {Silber, Jeffrey H. and Rosenbaum, Paul R. and Ross, Richard N. and Ludwig, Justin M. and Wang, Wei and Niknam, Bijan A. and Mukherjee, Nabanita and Saynisch, Philip A. and Even-Shoshan, Orit and Kelz, Rachel R. and Fleisher, Lee A.},
  journal  = {Health Services Research},
  title    = {Template Matching for Auditing Hospital Cost and Quality},
  year     = {2014},
  number   = {5},
  pages    = {1446-1474},
  volume   = {49},
  abstract = {Objective Develop an improved method for auditing hospital cost and quality. Data Sources/Setting Medicare claims in general, gynecologic and urologic surgery, and orthopedics from Illinois, Texas, and New York between 2004 and 2006. Study Design A template of 300 representative patients was constructed and then used to match 300 patients at hospitals that had a minimum of 500 patients over a 3-year study period. Data Collection/Extraction Methods From each of 217 hospitals we chose 300 patients most resembling the template using multivariate matching. Principal Findings The matching algorithm found close matches on procedures and patient characteristics, far more balanced than measured covariates would be in a randomized clinical trial. These matched samples displayed little to no differences across hospitals in common patient characteristics yet found large and statistically significant hospital variation in mortality, complications, failure-to-rescue, readmissions, length of stay, ICU days, cost, and surgical procedure length. Similar patients at different hospitals had substantially different outcomes. Conclusion The template-matched sample can produce fair, directly standardized audits that evaluate hospitals on patients with similar characteristics, thereby making benchmarking more believable. Through examining matched samples of individual patients, administrators can better detect poor performance at their hospitals and better understand why these problems are occurring.},
  doi      = {https://doi.org/10.1111/1475-6773.12156},
  eprint   = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/1475-6773.12156},
  keywords = {Quality of care, outcomes research, health care research, cost},
  url      = {https://onlinelibrary.wiley.com/doi/abs/10.1111/1475-6773.12156},
}






@Article{CesaBianchi2021,
  author   = {Cesa-Bianchi, Nicol\`{o} and Orabona, Francesco},
  journal  = {Annual Review of Statistics and Its Application},
  title    = {Online Learning Algorithms},
  year     = {2021},
  number   = {1},
  pages    = {165-190},
  volume   = {8},
  abstract = {Online learning is a framework for the design and analysis of algorithms that build predictive models by processing data one at the time. Besides being computationally efficient, online algorithms enjoy theoretical performance guarantees that do not rely on statistical assumptions on the data source. In this review, we describe some of the most important algorithmic ideas behind online learning and explain the main mathematical tools for their analysis. Our reference framework is online convex optimization, a sequential version of convex optimization within which most online algorithms are formulated. More specifically, we provide an in-depth description of online mirror descent and follow the regularized leader, two of the most fundamental algorithms in online learning. As the tuning of parameters is a typically difficult task in sequential data analysis, in the last part of the review we focus on coin-betting, an information-theoretic approach to the design of parameter-free online algorithms with good theoretical guarantees.},
  doi      = {10.1146/annurev-statistics-040620-035329},
  eprint   = {https://doi.org/10.1146/annurev-statistics-040620-035329},
  url      = {https://doi.org/10.1146/annurev-statistics-040620-035329},
}

@Article{Vazirani2012,
  author     = {Vazirani, Vijay V.},
  journal    = {J. ACM},
  title      = {The Notion of a Rational Convex Program, and an Algorithm for the Arrow-Debreu Nash Bargaining Game},
  year       = {2012},
  issn       = {0004-5411},
  month      = {may},
  number     = {2},
  volume     = {59},
  abstract   = {We introduce the notion of a rational convex program (RCP) and we classify the known RCPs into two classes: quadratic and logarithmic. The importance of rationality is that it opens up the possibility of computing an optimal solution to the program via an algorithm that is either combinatorial or uses an LP-oracle. Next, we define a new Nash bargaining game, called ADNB, which is derived from the linear case of the Arrow-Debreu market model. We show that the convex program for ADNB is a logarithmic RCP, but unlike other known members of this class, it is nontotal.Our main result is a combinatorial, polynomial-time algorithm for ADNB. It turns out that the reason for infeasibility of logarithmic RCPs is quite different from that for LPs and quadratic RCPs. We believe that our ideas for surmounting the new difficulties will be useful for dealing with other nontotal RCPs as well. We give an application of our combinatorial algorithm for ADNB to an important “fair” throughput allocation problem on a wireless channel. Finally, we present a number of interesting questions that the new notion of RCP raises.},
  address    = {New York, NY, USA},
  articleno  = {7},
  doi        = {10.1145/2160158.2160160},
  issue_date = {April 2012},
  numpages   = {36},
  priority   = {prio2},
  publisher  = {Association for Computing Machinery},
  ranking    = {rank5},
  url        = {https://doi.org/10.1145/2160158.2160160},
}

@Book{Lovasz1986,
  author    = {Lovász, László and Plummer, M. D.},
  publisher = {North-Holland : Elsevier Science Publishers B.V. ; Sole distributors for the U.S.A. and Canada, Elsevier Science Pub. Co.},
  title     = {Matching theory},
  year      = {1986},
  address   = {Amsterdam ; New York New York, N.Y.},
  isbn      = {0444879161 (pbk.)},
  note      = {87117473 by L. Lovász and M.D. Plummer. ill. ; 24 cm. Bibliography: p. [483]-526. Includes indexes.},
  series    = {North-Holland mathematics studies},
  keywords  = {Matching theory.},
  pages     = {xxxiii, 544 p.},
  type      = {Book},
}

@Book{Groetschel1988,
  author    = {Martin Gr{\"{o}}tschel and L{\'{a}}szl{\'{o}} Lov{\'{a}}sz and Alexander Schrijver},
  publisher = {Springer},
  title     = {Geometric Algorithms and Combinatorial Optimization},
  year      = {1988},
  isbn      = {978-3-642-97883-8},
  series    = {Algorithms and Combinatorics},
  volume    = {2},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  biburl    = {https://dblp.org/rec/books/sp/GLS1988.bib},
  doi       = {10.1007/978-3-642-97881-4},
  timestamp = {Tue, 06 Aug 2019 16:18:32 +0200},
  url       = {https://doi.org/10.1007/978-3-642-97881-4},
}

@Book{Lovasz1993,
  author    = {L{\'{a}}szl{\'{o}} Lov{\'{a}}sz},
  publisher = {North-Holland},
  title     = {Combinatorial problems and exercises {(2.} ed.)},
  year      = {1993},
  isbn      = {978-0-444-81504-0},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  biburl    = {https://dblp.org/rec/books/daglib/0077415.bib},
  timestamp = {Tue, 06 Aug 2019 16:18:32 +0200},
}

@Inbook{Plummer2008,
author="Plummer, Michael D.",
editor="Gr{\"o}tschel, Martin
and Katona, Gyula O. H.
and S{\'a}gi, G{\'a}bor",
title="Recent Progress in Matching Extension",
bookTitle="Building Bridges: Between Mathematics and Computer Science",
year="2008",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="427--454",
abstract="Let G be a graph with at least 2n+2 vertices, where n is a non-negative integer. The graph G is said to be n-extendable if every matching of size n in G extends to (i.e., is a subset of) a perfect matching. The study of this concept began in earnest in the 1980's, although it was born out of the study of canonical matching decompositions carried out in the 1970's and before. As is often the case, in retrospect it is apparent that there are roots of this topic to be found even earlier.",
isbn="978-3-540-85221-6",
doi="10.1007/978-3-540-85221-6_14",
url="https://doi.org/10.1007/978-3-540-85221-6_14"
}

@InBook{Csikvari2019,
  author    = {Csikv{\'a}ri, P{\'e}ter},
  editor    = {B{\'a}r{\'a}ny, Imre and Katona, Gyula O. H. and Sali, Attila},
  pages     = {195--221},
  publisher = {Springer Berlin Heidelberg},
  title     = {Statistical Matching Theory},
  year      = {2019},
  address   = {Berlin, Heidelberg},
  isbn      = {978-3-662-59204-5},
  abstract  = {In this paper, we survey some recent developments on statistical properties of matchings of very large and infinite graphs. We discuss extremal graph theoretic results like Schrijver's theorem on the number of perfect matchings of regular bipartite graphs and its variants from the point of view of graph limit theory. We also study the number of matchings of finite and infinite vertex-transitive graphs.},
  booktitle = {Building Bridges II: Mathematics of L{\'a}szl{\'o} Lov{\'a}sz},
  doi       = {10.1007/978-3-662-59204-5_5},
  url       = {https://doi.org/10.1007/978-3-662-59204-5_5},
}

 
@Book{Fan2020,
  author    = {Fan, Jianqing and Li, Runze and Zhang, Cun-Hui and Zou, Hui},
  publisher = {Chapman and Hall/CRC},
  title     = {Statistical Foundations of Data Science},
  year      = {2020},
  isbn      = {9780429096280},
  month     = sep,
  doi       = {10.1201/9780429096280},
}

@Inbook{Feige2019,
author="Feige, Uriel",
editor="B{\'a}r{\'a}ny, Imre
and Katona, Gyula O. H.
and Sali, Attila",
title="Tighter Bounds for Online Bipartite Matching",
bookTitle="Building Bridges II: Mathematics of L{\'a}szl{\'o} Lov{\'a}sz",
year="2019",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="235--255",
abstract="We study the online bipartite matching problem, introduced by Karp, Vazirani and Vazirani [1990]. For bipartite graphs with matchings of size n, it is known that the Ranking randomized algorithm matches at least {\$}{\$}(1 - {\backslash}frac{\{}1{\}}{\{}e{\}})n{\$}{\$} edges in expectation. It is also known that no online algorithm matches more than {\$}{\$}(1 - {\backslash}frac{\{}1{\}}{\{}e{\}})n + O(1){\$}{\$} edges in expectation, when the input is chosen from a certain distribution that we refer to as {\$}{\$}D{\_}n{\$}{\$}. This upper bound also applies to fractional matchings. We review the known proofs for this last statement. In passing we observe that the O(1) additive term (in the upper bound for fractional matching) is {\$}{\$}{\backslash}frac{\{}1{\}}{\{}2{\}} - {\backslash}frac{\{}1{\}}{\{}2e{\}} + O({\backslash}frac{\{}1{\}}{\{}n{\}}){\$}{\$}, and that this term is tight: the online algorithm known as Balance indeed produces a fractional matching of this size. We provide a new proof that exactly characterizes the expected cardinality of the (integral) matching produced by Ranking when the input graph comes from the support of {\$}{\$}D{\_}n{\$}{\$}. This expectation turns out to be {\$}{\$}(1 - {\backslash}frac{\{}1{\}}{\{}e{\}})n + 1 - {\backslash}frac{\{}2{\}}{\{}e{\}} + O({\backslash}frac{\{}1{\}}{\{}n!{\}}){\$}{\$}, and serves as an upper bound on the performance ratio of any online (integral) matching algorithm.",
isbn="978-3-662-59204-5",
doi="10.1007/978-3-662-59204-5_7",
url="https://doi.org/10.1007/978-3-662-59204-5_7"
}

@Book{Lovasz2019,
  author    = {Lovász, László},
  publisher = {American Mathematical Society},
  title     = {Graphs and geometry},
  year      = {2019},
  address   = {Providence, Rhode Island},
  isbn      = {9781470450878 (alk. paper)},
  note      = {2019011532 Laszlo Lovasz. illustrations ; 27 cm Includes bibliographical references (pages 421-436) and indexes.},
  series    = {American Mathematical Society colloquium publications},
  keywords  = {Mathematics Graphic methods. Geometry Graphic methods. Graph theory. Representations of graphs. Geometry. Combinatorics -- Graph theory -- None of the above, but in this section.},
  pages     = {x, 444 pages},
  type      = {Book},
}

@Article{Demartini2023,
  author     = {Demartini, Gianluca and Roitero, Kevin and Mizzaro, Stefano},
  journal    = {Commun. ACM},
  title      = {Data Bias Management},
  year       = {2023},
  issn       = {0001-0782},
  month      = {dec},
  number     = {1},
  pages      = {28–32},
  volume     = {67},
  abstract   = {Envisioning a unique approach toward bias and fairness research.},
  address    = {New York, NY, USA},
  doi        = {10.1145/3611641},
  issue_date = {January 2024},
  numpages   = {5},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/3611641},
}

@Book{Alon2016,
  author    = {Alon, Noga and Spencer, Joel H.},
  publisher = {Wiley},
  title     = {The probabilistic method},
  year      = {2016},
  address   = {Hoboken, New Jersey},
  edition   = {Fourth edition.},
  isbn      = {9781119061953 (cloth)},
  note      = {2015021599 Noga Alon, Joel H. Spencer. illustrations ; 24 cm Includes bibliographical references (pages [355]-365) and indexes.},
  keywords  = {Combinatorial analysis. Probabilities.},
  pages     = {xiv, 375 pages},
  type      = {Book},
}

@InProceedings{Garg2023,
  author    = {Garg, Jugal and Husi\'{c}, Edin and Li, Wenzheng and V\'{e}gh, L\'{a}szl\'{o} A. and Vondr\'{a}k, Jan},
  booktitle = {Proceedings of the 55th Annual ACM Symposium on Theory of Computing},
  title     = {Approximating Nash Social Welfare by Matching and Local Search},
  year      = {2023},
  address   = {New York, NY, USA},
  pages     = {1298–1310},
  publisher = {Association for Computing Machinery},
  series    = {STOC 2023},
  abstract  = {For any >0, we give a simple, deterministic (4+)-approximation algorithm for the Nash social welfare (NSW) problem under submodular valuations. The previous best approximation factor was 380 via a randomized algorithm. We also consider the asymmetric variant of the problem, where the objective is to maximize the weighted geometric mean of agents’ valuations, and give an (ω + 2 + ) -approximation if the ratio between the largest weight and the average weight is at most ω. We also show that the 12-EFX envy-freeness property can be attained simultaneously with a constant-factor approximation. More precisely, we can find an allocation in polynomial time which is both 12-EFX and a (8+)-approximation to the symmetric NSW problem under submodular valuations. The previous best approximation factor under 12-EFX was linear in the number of agents.},
  doi       = {10.1145/3564246.3585255},
  isbn      = {9781450399135},
  keywords  = {Approximation Algorithms, Local Search, Envy-freeness, Nash Social Welfare, Combinatorial Optimization, Fairness},
  location  = {Orlando, FL, USA},
  numpages  = {13},
  ranking   = {rank3},
  url       = {https://doi.org/10.1145/3564246.3585255},
}

@Article{Chaudhury2022,
  author     = {Chaudhury, Bhaskar Ray and Cheung, Yun Kuen and Garg, Jugal and Garg, Naveen and Hoefer, Martin and Mehlhorn, Kurt},
  journal    = {J. Artif. Int. Res.},
  title      = {Fair Division of Indivisible Goods for a Class of Concave Valuations},
  year       = {2022},
  issn       = {1076-9757},
  month      = {sep},
  volume     = {74},
  abstract   = {We study the fair and efficient allocation of a set of indivisible goods among agents, where each good has several copies, and each agent has an additively separable concave valuation function with a threshold. These valuations capture the property of diminishing marginal returns, and they are more general than the well-studied case of additive valuations. We present a polynomial-time algorithm that approximates the optimal Nash social welfare (NSW) up to a factor of e1/e ≈ 1.445. This matches with the state-of-the-art approximation factor for additive valuations. The computed allocation also satisfies the popular fairness guarantee of envy-freeness up to one good (EF1) up to a factor of 2 + ε. For instances without thresholds, it is also approximately Pareto-optimal. For instances satisfying a large market property, we show an improved approximation factor. Lastly, we show that the upper bounds on the optimal NSW introduced in Cole and Gkatzelis (2018) and Barman et al. (2018) have the same value.},
  address    = {El Segundo, CA, USA},
  doi        = {10.1613/jair.1.12911},
  issue_date = {Sep 2022},
  numpages   = {32},
  publisher  = {AI Access Foundation},
  url        = {https://doi.org/10.1613/jair.1.12911},
}

@InProceedings{Cole2017,
  author    = {Cole, Richard and Devanur, Nikhil and Gkatzelis, Vasilis and Jain, Kamal and Mai, Tung and Vazirani, Vijay V. and Yazdanbod, Sadra},
  booktitle = {Proceedings of the 2017 ACM Conference on Economics and Computation},
  title     = {Convex Program Duality, Fisher Markets, and Nash Social Welfare},
  year      = {2017},
  address   = {New York, NY, USA},
  pages     = {459–460},
  publisher = {Association for Computing Machinery},
  series    = {EC '17},
  doi       = {10.1145/3033274.3085109},
  isbn      = {9781450345279},
  keywords  = {fisher market, nash social welfare, convex program duality},
  location  = {Cambridge, Massachusetts, USA},
  numpages  = {2},
  ranking   = {rank3},
  url       = {https://doi.org/10.1145/3033274.3085109},
}

@Article{Amanatidis2023,
  author   = {Georgios Amanatidis and Haris Aziz and Georgios Birmpas and Aris Filos-Ratsikas and Bo Li and Hervé Moulin and Alexandros A. Voudouris and Xiaowei Wu},
  journal  = {Artificial Intelligence},
  title    = {Fair division of indivisible goods: Recent progress and open questions},
  year     = {2023},
  issn     = {0004-3702},
  pages    = {103965},
  volume   = {322},
  abstract = {Allocating resources to individuals in a fair manner has been a topic of interest since ancient times, with most of the early mathematical work on the problem focusing on resources that are infinitely divisible. Over the last decade, there has been a surge of papers studying computational questions regarding the indivisible case, for which exact fairness notions such as envy-freeness and proportionality are hard to satisfy. One main theme in the recent research agenda is to investigate the extent to which their relaxations, like maximin share fairness (MMS) and envy-freeness up to any good (EFX), can be achieved. In this survey, we present a comprehensive review of the recent progress made in the related literature by highlighting different ways to relax fairness notions, common algorithm design techniques, and the most interesting questions for future research.},
  doi      = {https://doi.org/10.1016/j.artint.2023.103965},
  groups   = {ideas},
  keywords = {Discrete fair division, Envy-freeness, Proportionality, EF1, EFX, MMS},
  url      = {https://www.sciencedirect.com/science/article/pii/S000437022300111X},
}

@InProceedings{Madan2020,
  author    = {Madan, Vivek and Nikolov, Aleksandar and Singh, Mohit and Tantipongpipat, Uthaipon},
  booktitle = {2020 IEEE 61st Annual Symposium on Foundations of Computer Science (FOCS)},
  title     = {Maximizing Determinants under Matroid Constraints},
  year      = {2020},
  pages     = {565-576},
  doi       = {10.1109/FOCS46700.2020.00059},
}

@InProceedings{Brown2022a,
  author          = {Adam Brown and Aditi Laddha and Madhusudhan Pittu and Mohit Singh and Prasad Tetali},
  title           = {Determinant Maximization via Matroid Intersection Algorithms},
  year            = {2022},
  address         = {Denver, CO, USA},
  pages           = {255--266},
  publisher       = {IEEE},
  abstract        = {Determinant maximization problem gives a general framework that models problems arising in as diverse fields as statistics [1], convex geometry [2], fair allocations [3], combinatorics [4], spectral graph theory [5], network design, and random processes [6]. In an instance of a determinant maximization problem, we are given a collection of vectors $U=\{v_{1},\cdots,\ v_{n}\}\subset \mathbb{R}^{d}$, and a goal is to pick a subset $S\subseteq U$ of given vectors to maximize the determinant of the matrix $\displaystyle \sum_{i\in S}v_{i}v_{i}^{\text{T}}$. Often, the set S of picked vectors must satisfy additional combinatorial constraints such as cardinality constraint $(|S|\leq k)$ or matroid constraint $(S$ is a basis of a matroid defined on the vectors). In this paper, we give a polynomial-time deterministic algorithm that returns a $r^{O(r)}$-approximation for any matroid of rank $r \leq d$. This improves previous results that give $e^{O(r^{2})}$-approximation algorithms relying on $e^{O(r)}$-approximate estimation algorithms [4], [7] –[9] for any r$\leq$d. All previous results use convex relaxations and their relationship to stable polynomials and strongly $\log$-concave polynomials or non-convex relaxations for the problem [10]. In contrast, our algorithm builds on combinatorial algorithms for matroid intersection, which iteratively improve any solution by finding an alternating negative cycle in the exchange graph defined by the matroids. While the $\det(.)$ function is not linear, we show that taking appropriate linear approximations at each iteration suffice to give the improved approximation algorithm.},
  date            = {31 Oct.-3 Nov. 2022},
  doi             = {10.1109/FOCS54457.2022.00031},
  eventdate       = {31 Oct.-3 Nov. 2022},
  eventtitleaddon = {Denver, CO, USA},
  file            = {:https\://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9996897:PDF},
  isbn            = {978-1-6654-5520-6},
  issn            = {1523-8288},
  journal         = {2022 IEEE 63rd Annual Symposium on Foundations of Computer Science (FOCS)},
  keywords        = {Geometry, Computer science, Linear approximation, Estimation, Approximation algorithms, Graph theory, Random processes, Computations on discrete structures, Combinatorial algorithms},
  ranking         = {rank3},
}

@Conference{Barman2018,
  author    = {Barman, Siddharth and Krishnamurthy, Sanath Kumar and Vaish, Rohit},
  booktitle = {Proceedings of the 17th International Conference on Autonomous Agents and MultiAgent Systems},
  title     = {Greedy Algorithms for Maximizing Nash Social Welfare},
  year      = {2018},
  address   = {Richland, SC},
  month     = {7},
  pages     = {7–13},
  publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
  series    = {AAMAS '18},
  abstract  = {We study the problem of fairly allocating a set of indivisible goods among agents with additive valuations. The extent of fairness of an allocation is measured by its Nash social welfare, which is the geometric mean of the valuations of the agents for their bundles. While the problem of maximizing Nash social welfare is known to be APX-hard in general, we study the effectiveness of simple, greedy algorithms in solving this problem in two interesting special cases.First, we show that a simple, greedy algorithm provides a 1.061-approximation guarantee when agents have identical valuations, even though the problem of maximizing Nash social welfare remains NP-hard for this setting. Second, we show that when agents have binary valuations over the goods, an exact solution (i.e., a Nash optimal allocation) can be found in polynomial time via a greedy algorithm. Our results in the binary setting extend to provide novel, exact algorithms for optimizing Nash social welfare under concave valuations. Notably, for the above mentioned scenarios, our techniques provide a simple alternative to several of the existing, more sophisticated techniques for this problem such as constructing equilibria of Fisher markets or using real stable polynomials.},
  day       = {9},
  keywords  = {approximation algorithms, fair division, greedy algorithms, nash social welfare},
  location  = {Stockholm, Sweden},
  pagetotal = {7},
}

@Conference{Peysakhovich2023a,
  author    = {Peysakhovich, Alexander and Kroer, Christian and Usunier, Nicolas},
  booktitle = {Proceedings of the 2023 ACM Conference on Fairness, Accountability, and Transparency},
  title     = {Implementing Fairness Constraints in Markets Using Taxes and Subsidies},
  year      = {2023},
  address   = {New York, NY, USA},
  month     = {6},
  pages     = {916–930},
  publisher = {Association for Computing Machinery},
  series    = {FAccT '23},
  abstract  = {Fisher markets are those where buyers with budgets compete for scarce items, a natural model for many real world markets including online advertising. A market equilibrium is a set of prices and allocations of items such that supply meets demand. We show how market designers can use taxes or subsidies in Fisher markets to ensure that market equilibrium outcomes fall within certain constraints. We show how these taxes and subsidies can be computed even in an online setting where the market designer does not have access to private valuations. We adapt various types of fairness constraints proposed in existing literature to the market case and show who benefits and who loses from these constraints, as well as the extent to which properties of markets including Pareto optimality, envy-freeness, and incentive compatibility are preserved. We find that some prior discussed constraints have few guarantees in terms of who is made better or worse off by their imposition.},
  day       = {12},
  doi       = {10.1145/3593013.3594051},
  isbn      = {9798400701924},
  location  = {Chicago, IL, USA},
  pagetotal = {15},
  ranking   = {rank5},
  url       = {https://doi.org/10.1145/3593013.3594051},
}

@InProceedings{Akrami2023,
  author    = {Akrami, Hannaneh and Alon, Noga and Chaudhury, Bhaskar Ray and Garg, Jugal and Mehlhorn, Kurt and Mehta, Ruta},
  booktitle = {Proceedings of the 24th ACM Conference on Economics and Computation},
  title     = {EFX: A Simpler Approach and an (Almost) Optimal Guarantee via Rainbow Cycle Number},
  year      = {2023},
  address   = {New York, NY, USA},
  pages     = {61},
  publisher = {Association for Computing Machinery},
  series    = {EC '23},
  abstract  = {The existence of EFX allocations is a fundamental open problem in discrete fair division. Since the general problem has been elusive, progress is made on two fronts: (i) proving existence when the number of agents is small, and (ii) proving the existence of relaxations of EFX. In this paper, we improve and simplify the state-of-the-art results on both fronts with new techniques.},
  doi       = {10.1145/3580507.3597799},
  isbn      = {9798400701047},
  location  = {London, United Kingdom},
  numpages  = {1},
  ranking   = {rank5},
  url       = {https://doi.org/10.1145/3580507.3597799},
}

@InProceedings{Durvasula2023,
  author    = {Durvasula, Naveen and Haghtalab, Nika and Zampetakis, Manolis},
  booktitle = {Proceedings of the 24th ACM Conference on Economics and Computation},
  title     = {Smoothed Analysis of Online Non-Parametric Auctions},
  year      = {2023},
  address   = {New York, NY, USA},
  pages     = {540–560},
  publisher = {Association for Computing Machinery},
  series    = {EC '23},
  abstract  = {Online learning of revenue-optimal auctions is a fundamental problem in mechanism design without priors. Nevertheless, all the existing positive results assume that the auctioneer optimizes over a parameterized class of auctions, such as pricings and auctions with reserves. This is perhaps not surprising given that natural correlations that occur in online sequences pose a challenge to characterizing a succinct class of revenue-optimal auctions. This has left behind a significant gap in our understanding of online-learnability of general classes of non-parametric auctions.We provide the first positive results for online learnability of a non-parametric auction class, for smooth adversaries and the class of smooth auctions. In a nutshell, an online adversary is smooth (in the style of Smoothed analysis [Spielman and Teng, 2004] in online learning [Haghtalab et al., 2021]) if the bid distribution has bounded density at every time step, and an auction is smooth if the level sets of its revenue function have small boundaries. We prove the following fundamental guarantees:(1) Revenue maximization in the class of smooth auctions is online-learnable, against smooth adversaries.(2) It is impossible to construct a no-regret algorithm even for the class of smooth auctions against worst-case adversaries.(3) It is impossible to construct a no-regret algorithm for the class of all incentive-compatible auctions even against smooth adversaries.This gives a strong characterization of when and which class of non-parametric auctions are online-learnable.To illustrate the generality of the class of smooth auctions we show that it contains the class of all monotone-revenue auctions, as well as, the class of all competition-monotone auctions. This brings up an interesting observation: while independence across bids leads to the optimal auctions being monotone, significantly weaker assumptions, compared to monotonicity of revenue, are sufficient for learnability.},
  doi       = {10.1145/3580507.3597787},
  isbn      = {9798400701047},
  keywords  = {online learning, learning in auctions, smoothed analysis, nonparametric auctions},
  location  = {London, United Kingdom},
  numpages  = {21},
  url       = {https://doi.org/10.1145/3580507.3597787},
}

@Conference{Dobzinski2023,
  author    = {Dobzinski, Shahar and Oren, Sigal and Vondrak, Jan},
  booktitle = {Proceedings of the 24th ACM Conference on Economics and Computation},
  title     = {Fairness and Incentive Compatibility via Percentage Fees},
  year      = {2023},
  address   = {New York, NY, USA},
  month     = {7},
  pages     = {517–535},
  publisher = {Association for Computing Machinery},
  series    = {EC '23},
  abstract  = {We study incentive-compatible mechanisms that maximize the Nash Social Welfare. Since traditional incentive-compatible mechanisms cannot maximize the Nash Social Welfare even approximately, we propose changing the traditional model. Inspired by a widely used charging method (e.g., royalties, a lawyer that charges some percentage of possible future compensation), we suggest charging the players some percentage of their value of the outcome. We call this model the percentage fee model.We show that there is a mechanism that maximizes exactly the Nash Social Welfare in every setting with non-negative valuations. Moreover, we prove an analog of Roberts theorem that essentially says that if the valuations are non-negative, then the only implementable social choice functions are those that maximize weighted variants of the Nash Social Welfare. We develop polynomial time incentive compatible approximation algorithms for the Nash Social Welfare with subadditive valuations and prove some hardness results.},
  day       = {7},
  doi       = {10.1145/3580507.3597810},
  isbn      = {9798400701047},
  location  = {London, United Kingdom},
  pagetotal = {19},
  ranking   = {rank4},
  url       = {https://doi.org/10.1145/3580507.3597810},
}

@Conference{Banerjee2023,
  author    = {Banerjee, Siddhartha and Eichhorn, Matthew and Kempe, David},
  booktitle = {Proceedings of the 24th ACM Conference on Economics and Computation},
  title     = {Allocating with Priorities and Quotas: Algorithms, Complexity, and Dynamics},
  year      = {2023},
  address   = {New York, NY, USA},
  month     = {7},
  pages     = {209–240},
  publisher = {Association for Computing Machinery},
  series    = {EC '23},
  abstract  = {In many applications such as rationing medical care and supplies, university admissions, and the assignment of public housing, the decision of who receives an allocation can be justified by various normative criteria (ethical, financial, legal, etc.). Such settings have motivated the following priority-respecting allocation problem: several categories, each with a quota of interchangeable items, wish to allocate the items among a set of agents. Each category has a list of eligible agents and a priority ordering over these agents; agents may be eligible in multiple categories. The goal is to select a valid allocation: one that respects quotas, eligibility, and priorities and ensures Pareto efficiency.We provide a complete algorithmic characterization of all valid allocations, exhibiting a bijection between sets of agents who can be allocated and maximum-weight matchings under carefully chosen rank-based weights. While prior work provides a polynomial-time algorithm to locate a valid allocation, our characterization admits a simpler algorithm that enables two wide-reaching extensions:1. Selecting valid allocations that satisfy additional criteria: Via three examples --- inclusion/exclusion of some chosen agent; agent-side Pareto efficiency vs. welfare maximization; and fairness from the perspective of allocated vs. unallocated agents --- we show that finding priority-respecting allocations subject to some secondary constraint straddles a complexity knife-edge; in each example, one problem variant can be solved efficiently, while a closely related variant is NP-hard.2. Efficiency-envy tradeoffs in dynamic allocation: In settings where allocations must be made to T agents arriving sequentially via some stochastic process, we show that while insisting on zero priority violations leads to an Ω(T) loss in efficiency, one can design allocation policies ensuring that the sum of the efficiency loss and priority violations in hindsight is O(1) (under mild regularity conditions on the arrival process).},
  day       = {7},
  doi       = {10.1145/3580507.3597733},
  isbn      = {9798400701047},
  keywords  = {online allocation, pareto efficiency, priorities, public goods, quotas},
  location  = {London, United Kingdom},
  pagetotal = {32},
  ranking   = {rank4},
  url       = {https://doi.org/10.1145/3580507.3597733},
}

@Inbook{Kroer2022,
author="Kroer, Christian
and Stier-Moses, Nicolas E.",
editor="Babich, Volodymyr
and Birge, John R.
and Hilary, Gilles",
title="Market Equilibrium Models in Large-Scale Internet Markets",
bookTitle="Innovative Technology at the Interface of Finance and Operations: Volume II",
year="2022",
publisher="Springer International Publishing",
address="Cham",
pages="147--189",
abstract="Markets and their corresponding equilibrium concepts have traditionally been used as very powerful building blocks to find allocations and prices. This chapter provides examples of the use of Fisher markets in the technology industry. We focus on Internet advertising auctions, fair division problems, content recommendation systems, and robust abstractions of large-scale markets. After introducing these markets, we describe how these models fit the relevant application domains and what insights they can generate, exhibiting the most important theoretical and computational results from the recent literature on these topics.",
isbn="978-3-030-81945-3",
doi="10.1007/978-3-030-81945-3_7",
url="https://doi.org/10.1007/978-3-030-81945-3_7"
}

@Article{Caragiannis2019,
  author    = {Caragiannis, Ioannis and Kurokawa, David and Moulin, Hervé and Procaccia, Ariel D. and Shah, Nisarg and Wang, Junxing},
  title     = {The Unreasonable Fairness of Maximum Nash Welfare},
  year      = {2019},
  month     = {9},
  pages     = {1–32},
  abstract  = {The maximum Nash welfare (MNW) solution—which selects an allocation that maximizes the product of utilities—is known to provide outstanding fairness guarantees when allocating divisible goods. And while it seems to lose its luster when applied to indivisible goods, we show that, in fact, the MNW solution is strikingly fair even in that setting. In particular, we prove that it selects allocations that are envy-free up to one good—a compelling notion that is quite elusive when coupled with economic efficiency. We also establish that the MNW solution provides a good approximation to another popular (yet possibly infeasible) fairness property, the maximin share guarantee, in theory and—even more so—in practice. While finding the MNW solution is computationally hard, we develop a nontrivial implementation and demonstrate that it scales well on real data. These results establish MNW as a compelling solution for allocating indivisible goods and underlie its deployment on a popular fair-division website.},
  address   = {New York, NY, USA},
  booktitle = {ACM Trans. Econ. Comput.},
  day       = {24},
  doi       = {10.1145/3355902},
  keywords  = {Fair division, Nash welfare, resource allocation},
  pagetotal = {32},
  publisher = {Association for Computing Machinery},
  ranking   = {rank4},
  url       = {https://doi.org/10.1145/3355902},
}

@InProceedings{Anari2017,
  author    = {Nima Anari and Shayan Oveis Gharan and Amin Saberi and Mohit Singh},
  booktitle = {8th Innovations in Theoretical Computer Science Conference, {ITCS} 2017, January 9-11, 2017, Berkeley, CA, {USA}},
  title     = {Nash Social Welfare, Matrix Permanent, and Stable Polynomials},
  year      = {2017},
  editor    = {Christos H. Papadimitriou},
  pages     = {36:1--36:12},
  publisher = {Schloss Dagstuhl - Leibniz-Zentrum f{\"{u}}r Informatik},
  series    = {LIPIcs},
  volume    = {67},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  biburl    = {https://dblp.org/rec/conf/innovations/AnariGSS17.bib},
  doi       = {10.4230/LIPICS.ITCS.2017.36},
}

@Conference{Fain2018,
  author    = {Fain, Brandon and Munagala, Kamesh and Shah, Nisarg},
  booktitle = {Proceedings of the 2018 ACM Conference on Economics and Computation},
  title     = {Fair Allocation of Indivisible Public Goods},
  year      = {2018},
  address   = {New York, NY, USA},
  month     = {6},
  pages     = {575–592},
  publisher = {Association for Computing Machinery},
  series    = {EC '18},
  abstract  = {We consider the problem of fairly allocating indivisible public goods. We model the public goods as elements with feasibility constraints on what subsets of elements can be chosen, and assume that agents have additive utilities across elements. Our model generalizes existing frameworks such as fair public decision making and participatory budgeting. We study a groupwise fairness notion called the core, which generalizes well-studied notions of proportionality and Pareto efficiency, and requires that each subset of agents must receive an outcome that is fair relative to its size. In contrast to the case of divisible public goods (where fractional allocations are permitted), the core is not guaranteed to exist when allocating indivisible public goods. Our primary contributions are the notion of an additive approximation to the core (with a tiny multiplicative loss), and polynomial time algorithms that achieve a small additive approximation, where the additive factor is relative to the largest utility of an agent for an element. If the feasibility constraints define a matroid, we show an additive approximation of 2. A similar approach yields a constant additive bound when the feasibility constraints define a matching. For feasibility constraints defining an arbitrary packing polytope with mild restrictions, we show an additive guarantee that is logarithmic in the width of the polytope. Our algorithms are based on the convex program for maximizing the Nash social welfare, but differ significantly from previous work in how it is used. As far as we are aware, our work is the first to approximate the core in indivisible settings.},
  day       = {11},
  doi       = {10.1145/3219166.3219174},
  isbn      = {9781450358293},
  keywords  = {core, fairness, indivisible goods, proportionality, public goods},
  location  = {Ithaca, NY, USA},
  pagetotal = {18},
  url       = {https://doi.org/10.1145/3219166.3219174},
}

@Conference{Lev2021,
  author    = {Lev, Omer and Patel, Neel and Viswanathan, Vignesh and Zick, Yair},
  booktitle = {Proceedings of the 20th International Conference on Autonomous Agents and MultiAgent Systems},
  title     = {The Price is (Probably) Right: Learning Market Equilibria from Samples},
  year      = {2021},
  address   = {Richland, SC},
  month     = {5},
  pages     = {755–763},
  publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
  series    = {AAMAS '21},
  abstract  = {Equilibrium computation in markets usually considers settings where player valuation functions are known. We consider the setting where player valuations are unknown; using a PAC learning-theoretic framework, we analyze some classes of common valuation functions, and provide algorithms which output direct PAC equilibrium allocations, not estimates based on attempting to learn valuation functions. Since there exist trivial PAC market outcomes with an unbounded worst-case efficiency loss, we lower-bound the efficiency of our algorithms. While the efficiency loss under general distributions is rather high, we show that in some cases (e.g., unit-demand valuations), it is possible to find a PAC market equilibrium with significantly better utility.},
  day       = {3},
  isbn      = {9781450383073},
  keywords  = {fisher markets, market equilibria, pac learning},
  location  = {Virtual Event, United Kingdom},
  pagetotal = {9},
}

@Conference{Kroer2019,
  author    = {Kroer, Christian and Peysakhovich, Alexander and Sodomka, Eric and Stier-Moses, Nicolas E.},
  booktitle = {Proceedings of the 2019 ACM Conference on Economics and Computation},
  title     = {Computing Large Market Equilibria using Abstractions},
  year      = {2019},
  address   = {New York, NY, USA},
  month     = {6},
  pages     = {745–746},
  publisher = {Association for Computing Machinery},
  series    = {EC '19},
  abstract  = {Computing market equilibria is an important practical problem for market design (e.g. fair division, item allocation). However, computing equilibria requires large amounts of information (e.g. all valuations for all buyers for all items) and compute power. We consider ameliorating these issues by applying a method used for solving complex games: constructing a coarsened abstraction of a given market, solving for the equilibrium in the abstraction, and lifting the prices and allocations back to the original market. We show how to bound important quantities such as regret, envy, Nash social welfare, Pareto optimality, and maximin share when the abstracted prices and allocations are used in place of the real equilibrium. We then study two abstraction methods of interest for practitioners: 1) filling in unknown valuations using techniques from matrix completion, 2) reducing the problem size by aggregating groups of buyers/items into smaller numbers of representative buyers/items and solving for equilibrium in this coarsened market. We find that in real data allocations/prices that are relatively close to equilibria can be computed from even very coarse abstractions.},
  day       = {17},
  doi       = {10.1145/3328526.3329553},
  isbn      = {9781450367929},
  keywords  = {competitive equilibrium, eisenberg-gale formulation, fair division, game abstraction, market equilibrium},
  location  = {Phoenix, AZ, USA},
  pagetotal = {2},
  url       = {https://doi.org/10.1145/3328526.3329553},
}

@Conference{Alaei2017,
  author    = {Alaei, Saeed and Jalaly Khalilabadi, Pooya and Tardos, Eva},
  booktitle = {Proceedings of the 2017 ACM Conference on Economics and Computation},
  title     = {Computing Equilibrium in Matching Markets},
  year      = {2017},
  address   = {New York, NY, USA},
  month     = {6},
  pages     = {245–261},
  publisher = {Association for Computing Machinery},
  series    = {EC '17},
  abstract  = {Market equilibria of matching markets offer an intuitive and fair solution for matching problems without money with agents who have preferences over the items. Such a matching market can be viewed as a variation of Fisher market, albeit with rather peculiar preferences of agents. These preferences can be described by piece-wise linear concave (PLC) functions, which however, are not separable (due to each agent only asking for one item), are not monotone, and do not satisfy the gross substitute property-- increase in price of an item can result in increased demand for the item. Devanur and Kannan in FOCS 08 showed that market clearing prices can be found in polynomial time in markets with fixed number of items and general PLC preferences. They also consider Fischer markets with fixed number of agents (instead of fixed number of items), and give a polynomial time algorithm for this case if preferences are separable functions of the items, in addition to being PLC functions.Our main result is a polynomial time algorithm for finding market clearing prices in matching markets with fixed number of different agent preferences, despite that the utility corresponding to matching markets is not separable. We also give a simpler algorithm for the case of matching markets with fixed number of different items.},
  day       = {20},
  doi       = {10.1145/3033274.3085150},
  isbn      = {9781450345279},
  keywords  = {equilibrium computation, fairness, market equilibria, mechanism design without money},
  location  = {Cambridge, Massachusetts, USA},
  pagetotal = {17},
  url       = {https://doi.org/10.1145/3033274.3085150},
}

@Conference{Anari2023,
  author    = {Anari, Nima and Charikar, Moses and Ramakrishnan, Prasanna},
  booktitle = {Proceedings of the 24th ACM Conference on Economics and Computation},
  title     = {Distortion in metric matching with ordinal preferences},
  year      = {2023},
  address   = {New York, NY, USA},
  month     = {7},
  pages     = {90–110},
  publisher = {Association for Computing Machinery},
  series    = {EC '23},
  abstract  = {Suppose that we have n agents and n items which lie in a shared metric space. We would like to match the agents to items such that the total distance from agents to their matched items is as small as possible. However, instead of having direct access to distances in the metric, we only have each agent's ranking of the items in order of distance. Given this limited information, what is the minimum possible worst-case approximation ratio (known as the distortion) that a matching mechanism can guarantee?Previous work by Caragiannis et al. [2016] proved that the (deterministic) Serial Dictatorship mechanism has distortion at most 2n − 1. We improve this by providing a simple deterministic mechanism that has distortion O(n2). We also provide the first nontrivial lower bound on this problem, showing that any matching mechanism (deterministic or randomized) must have worst-case distortion Ω(log n).In addition to these new bounds, we show that a large class of truthful mechanisms derived from Deferred Acceptance all have worst-case distortion at least 2n − 1, and we find an intriguing connection between thin matchings (analogous to the well-known thin trees conjecture) and the distortion gap between deterministic and randomized mechanisms.},
  day       = {7},
  doi       = {10.1145/3580507.3597740},
  isbn      = {9798400701047},
  location  = {London, United Kingdom},
  pagetotal = {21},
  url       = {https://doi.org/10.1145/3580507.3597740},
}

@Conference{Cashore2022,
  author    = {Cashore, J. Massey and Frazier, Peter I. and Tardos, Eva},
  booktitle = {Proceedings of the 23rd ACM Conference on Economics and Computation},
  title     = {Dynamic Pricing Provides Robust Equilibria in Stochastic Ride-Sharing Networks},
  year      = {2022},
  address   = {New York, NY, USA},
  month     = {7},
  pages     = {301–302},
  publisher = {Association for Computing Machinery},
  series    = {EC '22},
  abstract  = {Ridesharing markets are complex: drivers are strategic, rider demand and driver availability are stochastic, and complex city-scale phenomena like weather induce large scale correlation across space and time. At the same time, past work has focused on a subset of these challenges. We propose a model of ridesharing networks with strategic drivers, spatiotemporal dynamics, and stochasticity. Supporting both computational tractability and better modeling flexibility than classical fluid limits, we use a two-level stochastic model that allows correlated shocks caused by weather or large public events.Using this model, we propose a novel pricing mechanism: stochastic spatiotemporal pricing (SSP). We show that the SSP mechanism is asymptotically incentive-compatible and that all (approximate) equilibria of the resulting game are asymptotically welfare-maximizing when the market is large enough. The SSP mechanism iteratively recomputes prices based on realized demand and supply, and in this sense prices dynamically. We show that this is critical: while a static variant of the SSP mechanism (whose prices vary with the market-level stochastic scenario but not individual rider and driver decisions) has a sequence of asymptotically welfare-optimal approximate equilibria, we demonstrate that it also has other equilibria producing extremely low social welfare. Thus, we argue that dynamic pricing is important for ensuring robustness in stochastic ride-sharing networks.},
  day       = {13},
  doi       = {10.1145/3490486.3538277},
  isbn      = {9781450391504},
  keywords  = {market design, pricing, ridesharing},
  location  = {Boulder, CO, USA},
  pagetotal = {2},
  url       = {https://doi.org/10.1145/3490486.3538277},
}

@Article{Vazirani2022,
  author        = {Vazirani, Vijay V.},
  title         = {Cores of Games via Total Dual Integrality, with Applications to Perfect Graphs and Polymatroids},
  year          = {2022},
  month         = sep,
  abstract      = {LP-duality theory has played a central role in the study of cores of games, right from the early days of this notion to the present time. The classic paper of Shapley and Shubik \cite{Shapley1971assignment} introduced the "right" way of exploiting the power of this theory, namely picking problems whose LP-relaxations support polyhedra having integral vertices. So far, the latter fact was established by showing that the constraint matrix of the underlying linear system is {\em totally unimodular}. We attempt to take this methodology to its logical next step -- {\em using total dual integrality} -- thereby addressing new classes of games which have their origins in two major theories within combinatorial optimization, namely perfect graphs and polymatroids. In the former, we address the stable set and clique games and in the latter, we address the matroid independent set game. For each of these games, we prove that the set of core imputations is precisely the set of optimal solutions to the dual LPs. Another novelty is the way the worth of the game is allocated among sub-coalitions. Previous works follow the {\em bottom-up process} of allocating to individual agents; the allocation to a sub-coalition is simply the sum of the allocations to its agents. The {\em natural process for our games is top-down}. The optimal dual allocates to "objects" in the grand coalition; a sub-coalition inherits the allocation of each object with which it has non-empty intersection.},
  archiveprefix = {arXiv},
  copyright     = {Creative Commons Attribution 4.0 International},
  doi           = {10.48550/ARXIV.2209.04903},
  eprint        = {2209.04903},
  file          = {:http\://arxiv.org/pdf/2209.04903v2:PDF},
  keywords      = {Computer Science and Game Theory (cs.GT), Data Structures and Algorithms (cs.DS), Theoretical Economics (econ.TH), FOS: Computer and information sciences, FOS: Economics and business},
  primaryclass  = {cs.GT},
  publisher     = {arXiv},
}

@Conference{Dutta2017,
  author    = {Dutta, Sourav and Nayek, Pratik and Bhattacharya, Arnab},
  booktitle = {Proceedings of the 26th International Conference on World Wide Web},
  title     = {Neighbor-Aware Search for Approximate Labeled Graph Matching using the Chi-Square Statistics},
  year      = {2017},
  address   = {Republic and Canton of Geneva, CHE},
  month     = {4},
  pages     = {1281–1290},
  publisher = {International World Wide Web Conferences Steering Committee},
  series    = {WWW '17},
  abstract  = {Labeled graphs provide a natural way of representing entities, relationships and structures within real datasets such as knowledge graphs and protein interactions. Applications such as question answering, semantic search, and motif discovery entail efficient approaches for subgraph matching involving both label and structural similarities. Given the NP-completeness of subgraph isomorphism and the presence of noise, approximate graph matching techniques are required to handle queries in a robust and real-time manner. This paper presents a novel technique to characterize the subgraph similarity based on statistical significance captured by chi-square statistic. The statistical significance model takes into account the background structure and label distribution in the neighborhood of vertices to obtain the best matching subgraph and, therefore, robustly handles partial label and structural mismatches. Based on the model, we propose two algorithms, VELSET and NAGA, that, given a query graph, return the top-k most similar subgraphs from a (large) database graph. While VELSET is more accurate and robust to noise, NAGA is faster and more applicable for scenarios with low label noise. Experiments on large real-life graph datasets depict significant improvements in terms of accuracy and running time in comparison to the state-of-the-art methods.},
  day       = {3},
  doi       = {10.1145/3038912.3052561},
  isbn      = {9781450349130},
  keywords  = {approximate subgraph matching, chi-square statistic, statistical significance, subgraph similarity},
  location  = {Perth, Australia},
  pagetotal = {10},
  url       = {https://doi.org/10.1145/3038912.3052561},
}

@Conference{Garg2023a,
  author    = {Garg, Jugal and Tröbst, Thorben and Vazirani, Vijay V.},
  booktitle = {Proceedings of the 2023 International Conference on Autonomous Agents and Multiagent Systems},
  title     = {A Nash-Bargaining-Based Mechanism for One-Sided Matching Markets and Dichotomous Utilities},
  year      = {2023},
  address   = {Richland, SC},
  month     = {5},
  pages     = {2721–2723},
  publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
  series    = {AAMAS '23},
  abstract  = {Mechanisms based on maximizing Nash Social Welfare (NSW) have proven to be fair and efficient for a wide variety of fair division problems. We study the fractional allocations maximizing NSW, i.e., a Nash-bargaining-based mechanism, for one-sided matching markets with endowments, under dichotomous utilities, and show that they are the solutions of a rational convex program (RCP). Moreover, we provide a simple combinatorial polynomial time algorithm to maximize NSW by identifying the Nash bargaining points with the equilibrium of a novel type of market, the variable-budget market model. Lastly, we show that maximizing NSW is strategyproof under the assumption that the agents' disagreement utilities are public knowledge.},
  day       = {30},
  isbn      = {9781450394321},
  keywords  = {dichotomous utilities, nash bargaining solution, rational convex program},
  location  = {London, United Kingdom},
  pagetotal = {3},
  ranking   = {rank4},
}

@Article{Anshelevich2010,
  author    = {Anshelevich, Elliot and Das, Sanmay},
  title     = {Matching, cardinal utility, and social welfare},
  year      = {2010},
  month     = {6},
  pages     = {1–7},
  abstract  = {Matching markets have historically been an important topic in economics research. On the positive (descriptive) side, researchers have modeled everything ranging from marriage markets to labor markets using the framework of matching. Matching was also one of the first areas in which market design made a name for itself, perhaps most famously in the redesign of the market that matches graduating M.D.s to their first residency programs in the United States. The arrival of computer scientists to the field of market design in general can be traced to many of the reasons suggested recently by Conitzer [2010] (in a broader context than just market design) in an article in Communications of the ACM, including the effects of new markets that have been made possible by advances in networking and Internet technology, a more computational mindset in general, and also the ability to view problems from a different perspective. In the case of matching markets in particular, in addition to the (often) constructive nature of computational approaches, there is also the historical fact that computer scientists have studied matching from many different perspectives, perhaps because matching markets have a very natural representation in the language of graphs.},
  address   = {New York, NY, USA},
  booktitle = {SIGecom Exch.},
  day       = {1},
  doi       = {10.1145/1980534.1980538},
  keywords  = {game theory, matching, utility},
  pagetotal = {7},
  publisher = {Association for Computing Machinery},
  ranking   = {rank5},
  url       = {https://doi.org/10.1145/1980534.1980538},
}

@Conference{Christodoulou2016,
  author    = {Christodoulou, George and Filos-Ratsikas, Aris and Frederiksen, Søren Kristoffer Stiil and Goldberg, Paul W. and Zhang, Jie and Zhang, Jinshan},
  booktitle = {Proceedings of the 2016 International Conference on Autonomous Agents & Multiagent Systems},
  title     = {Social Welfare in One-Sided Matching Mechanisms: (Extended Abstract)},
  year      = {2016},
  address   = {Richland, SC},
  month     = {5},
  pages     = {1297–1298},
  publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
  series    = {AAMAS '16},
  abstract  = {We study the Price of Anarchy of mechanisms for the well-known problem of one-sided matching, or house allocation, with respect to the social welfare objective. We consider both ordinal mechanisms, where agents submit preference lists over the items, and cardinal mechanisms, where agents may submit numerical values for the items being allocated. We present a general lower bound of Ω(√n) on the Price of Anarchy, which applies to all mechanisms and we show that a very well-known mechanisms, Probabilistic Serial achieves a matching upper bound. We extend our lower bound to the Price of Stability of a large class of mechanisms that satisfy a common proportionality property.},
  day       = {9},
  isbn      = {9781450342391},
  keywords  = {nash equilibrium, one-sided matching, price of anarchy, probabilistic serial, truthfulness},
  location  = {Singapore, Singapore},
  pagetotal = {2},
}

@Conference{Anari2018,
  author    = {Anari, Nima and Mai, Tung and Gharan, Shayan Oveis and Vazirani, Vijay V.},
  booktitle = {Proceedings of the Twenty-Ninth Annual ACM-SIAM Symposium on Discrete Algorithms},
  title     = {Nash social welfare for indivisible items under separable, piecewise-linear concave utilities},
  year      = {2018},
  address   = {USA},
  month     = {1},
  pages     = {2274–2290},
  publisher = {Society for Industrial and Applied Mathematics},
  series    = {SODA '18},
  abstract  = {Recently Cole and Gkatzelis [10] gave the first constant factor approximation algorithm for the problem of allocating indivisible items to agents, under additive valuations, so as to maximize the Nash social welfare (NSW). We give constant factor algorithms for a substantial generalization of their problem - to the case of separable, piecewise-linear concave utility functions. We give two such algorithms, the first using market equilibria and the second using the theory of real stable polynomials. Both approaches require new algorithmic ideas.},
  day       = {7},
  isbn      = {9781611975031},
  location  = {New Orleans, Louisiana},
  pagetotal = {17},
  ranking   = {rank3},
}

@Article{Bilo2022,
  author    = {Bilò, Vittorio and Monaco, Gianpiero and Moscardelli, Luca and Vinci, Cosimo},
  title     = {Nash Social Welfare in Selfish and Online Load Balancing},
  year      = {2022},
  month     = {10},
  pages     = {1–41},
  abstract  = {In load-balancing problems there is a set of clients, each wishing to select a resource from a set of permissible ones to execute a certain task. Each resource has a latency function, which depends on its workload, and a client’s cost is the completion time of her chosen resource. Two fundamental variants of load-balancing problems are selfish load balancing (a.k.a. load-balancing games), where clients are non-cooperative selfish players aimed at minimizing their own cost solely, and online load balancing, where clients appear online and have to be irrevocably assigned to a resource without any knowledge about future requests. We revisit both problems under the objective of minimizing the Nash Social Welfare, i.e., the geometric mean of the clients’ costs. To the best of our knowledge, despite being a celebrated welfare estimator in many social contexts, the Nash Social Welfare has not been considered so far as a benchmarking quality measure in load-balancing problems. We provide tight bounds on the price of anarchy of pure Nash equilibria and on the competitive ratio of the greedy algorithm under very general latency functions, including polynomial ones. For this particular class, we also prove that the greedy strategy is optimal, as it matches the performance of any possible online algorithm.},
  address   = {New York, NY, USA},
  booktitle = {ACM Trans. Econ. Comput.},
  day       = {7},
  doi       = {10.1145/3544978},
  keywords  = {Congestion games, Nash social welfare, online algorithms, price of anarchy, pure Nash equilibrium},
  pagetotal = {41},
  publisher = {Association for Computing Machinery},
  url       = {https://doi.org/10.1145/3544978},
}

@Article{Garg2023b,
  author    = {Garg, Jugal and Kulkarni, Pooja and Kulkarni, Rucha},
  title     = {Approximating Nash Social Welfare under Submodular Valuations through (Un)Matchings},
  year      = {2023},
  month     = {9},
  pages     = {1–25},
  abstract  = {We study the problem of approximating maximum Nash social welfare (NSW) when allocating m indivisible items among n asymmetric agents with submodular valuations. The NSW is a well-established notion of fairness and efficiency, defined as the weighted geometric mean of agents’ valuations. For special cases of the problem with symmetric agents and additive(-like) valuation functions, approximation algorithms have been designed using approaches customized for these specific settings, and they fail to extend to more general settings. Hence, no approximation algorithm with a factor independent of m was known either for asymmetric agents with additive valuations or for symmetric agents beyond additive(-like) valuations before this work.In this article, we extend our understanding of the NSW problem to far more general settings. Our main contribution is two approximation algorithms for asymmetric agents with additive and submodular valuations. Both algorithms are simple to understand and involve non-trivial modifications of a greedy repeated matchings approach. Allocations of high-valued items are done separately by un-matching certain items and re-matching them by different processes in both algorithms. We show that these approaches achieve approximation factors of O(n) and O(n log n) for additive and submodular cases, independent of the number of items. For additive valuations, our algorithm outputs an allocation that also achieves the fairness property of envy-free up to one item (EF1).Furthermore, we show that the NSW problem under submodular valuations is strictly harder than all currently known settings with an  \(\frac{\mathrm{e}}{\mathrm{e}-1}\)  factor of the hardness of approximation, even for constantly many agents. For this case, we provide a different approximation algorithm that achieves a factor of  \(\frac{\mathrm{e}}{\mathrm{e}-1}\) , hence resolving it completely.},
  address   = {New York, NY, USA},
  booktitle = {ACM Trans. Algorithms},
  day       = {26},
  doi       = {10.1145/3613452},
  keywords  = {Nash social welfare, asymmetric agents, submodular valuations},
  pagetotal = {25},
  publisher = {Association for Computing Machinery},
  url       = {https://doi.org/10.1145/3613452},
}

@Article{Brown2024,
  author        = {Adam Brown and Aditi Laddha and Madhusudhan Reddy Pittu and Mohit Singh},
  journal       = {CoRR},
  title         = {Approximation Algorithms for the Weighted Nash Social Welfare via Convex and Non-Convex Programs},
  year          = {2024},
  volume        = {abs/2401.02918},
  archiveprefix = {arXiv},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/journals/corr/abs-2401-02918.bib},
  doi           = {10.48550/ARXIV.2401.02918},
  eprint        = {2401.02918},
  ranking       = {rank4},
}

@Misc{Lovasz2023,
  author        = {László Lovász},
  title         = {Submodular setfunctions on sigma-algebras, version 2},
  year          = {2023},
  archiveprefix = {arXiv},
  eprint        = {2302.04704},
  primaryclass  = {math.CO},
}

@Misc{Lovasz2023a,
  author        = {László Lovász},
  title         = {The matroid of a graphing},
  year          = {2023},
  archiveprefix = {arXiv},
  eprint        = {2311.03868},
  primaryclass  = {math.CO},
}

@Article{Cappart2023,
  author    = {Quentin Cappart and Didier Ch{\'{e}}telat and Elias B. Khalil and Andrea Lodi and Christopher Morris and Petar Velickovic},
  journal   = {J. Mach. Learn. Res.},
  title     = {Combinatorial Optimization and Reasoning with Graph Neural Networks},
  year      = {2023},
  pages     = {130:1--130:61},
  volume    = {24},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  biburl    = {https://dblp.org/rec/journals/jmlr/CappartCK00V23.bib},
  url       = {http://jmlr.org/papers/v24/21-0449.html},
}

@Article{Fan2023,
  author        = {Jianqing Fan and Zhipeng Lou and Weichen Wang and Mengxin Yu},
  journal       = {CoRR},
  title         = {Spectral Ranking Inferences based on General Multiway Comparisons},
  year          = {2023},
  volume        = {abs/2308.02918},
  archiveprefix = {arXiv},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/journals/corr/abs-2308-02918.bib},
  doi           = {10.48550/ARXIV.2308.02918},
  eprint        = {2308.02918},
}

@Article{Fan2022,
  author        = {Jianqing Fan and Zhipeng Lou and Weichen Wang and Mengxin Yu},
  journal       = {CoRR},
  title         = {Ranking Inferences Based on the Top Choice of Multiway Comparisons},
  year          = {2022},
  volume        = {abs/2211.11957},
  archiveprefix = {arXiv},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/journals/corr/abs-2211-11957.bib},
  doi           = {10.48550/ARXIV.2211.11957},
  eprint        = {2211.11957},
}

@InProceedings{Mai2018,
  author    = {Tung Mai and Vijay V. Vazirani},
  booktitle = {26th Annual European Symposium on Algorithms, {ESA} 2018, August 20-22, 2018, Helsinki, Finland},
  title     = {Finding Stable Matchings That Are Robust to Errors in the Input},
  year      = {2018},
  editor    = {Yossi Azar and Hannah Bast and Grzegorz Herman},
  pages     = {60:1--60:11},
  publisher = {Schloss Dagstuhl - Leibniz-Zentrum f{\"{u}}r Informatik},
  series    = {LIPIcs},
  volume    = {112},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  biburl    = {https://dblp.org/rec/conf/esa/MaiV18.bib},
  doi       = {10.4230/LIPICS.ESA.2018.60},
  ranking   = {rank4},
}

@Article{Megow2022,
  author        = {Megow, Nicole and Schlöter, Jens},
  title         = {Set Selection under Explorable Stochastic Uncertainty via Covering Techniques},
  year          = {2022},
  month         = nov,
  abstract      = {Given subsets of uncertain values, we study the problem of identifying the subset of minimum total value (sum of the uncertain values) by querying as few values as possible. This set selection problem falls into the field of explorable uncertainty and is of intrinsic importance therein as it implies strong adversarial lower bounds for a wide range of interesting combinatorial problems such as knapsack and matchings. We consider a stochastic problem variant and give algorithms that, in expectation, improve upon these adversarial lower bounds. The key to our results is to prove a strong structural connection to a seemingly unrelated covering problem with uncertainty in the constraints via a linear programming formulation. We exploit this connection to derive an algorithmic framework that can be used to solve both problems under uncertainty, obtaining nearly tight bounds on the competitive ratio. This is the first non-trivial stochastic result concerning the sum of unknown values without further structure known for the set. With our novel methods, we lay the foundations for solving more general problems in the area of explorable uncertainty.},
  archiveprefix = {arXiv},
  copyright     = {Creative Commons Attribution 4.0 International},
  doi           = {10.48550/ARXIV.2211.01097},
  eprint        = {2211.01097},
  file          = {:http\://arxiv.org/pdf/2211.01097v2:PDF},
  keywords      = {Data Structures and Algorithms (cs.DS), FOS: Computer and information sciences},
  primaryclass  = {cs.DS},
  publisher     = {arXiv},
  ranking       = {rank3},
}

@Article{Devic2023,
  author        = {Devic, Siddartha and Kempe, David and Sharan, Vatsal and Korolova, Aleksandra},
  title         = {Fairness in Matching under Uncertainty},
  year          = {2023},
  month         = feb,
  abstract      = {The prevalence and importance of algorithmic two-sided marketplaces has drawn attention to the issue of fairness in such settings. Algorithmic decisions are used in assigning students to schools, users to advertisers, and applicants to job interviews. These decisions should heed the preferences of individuals, and simultaneously be fair with respect to their merits (synonymous with fit, future performance, or need). Merits conditioned on observable features are always \emph{uncertain}, a fact that is exacerbated by the widespread use of machine learning algorithms to infer merit from the observables. As our key contribution, we carefully axiomatize a notion of individual fairness in the two-sided marketplace setting which respects the uncertainty in the merits; indeed, it simultaneously recognizes uncertainty as the primary potential cause of unfairness and an approach to address it. We design a linear programming framework to find fair utility-maximizing distributions over allocations, and we show that the linear program is robust to perturbations in the estimated parameters of the uncertain merit distributions, a key property in combining the approach with machine learning techniques.},
  archiveprefix = {arXiv},
  copyright     = {Creative Commons Attribution Non Commercial No Derivatives 4.0 International},
  doi           = {10.48550/ARXIV.2302.03810},
  eprint        = {2302.03810},
  file          = {:http\://arxiv.org/pdf/2302.03810v2:PDF},
  keywords      = {Machine Learning (cs.LG), FOS: Computer and information sciences},
  primaryclass  = {cs.LG},
  publisher     = {arXiv},
  ranking       = {rank3},
}

@Book{Nisan2007,
  editor    = {Noam Nisan and Tim Roughgarden and {\'{E}}va Tardos and Vijay V. Vazirani},
  publisher = {Cambridge University Press},
  title     = {Algorithmic Game Theory},
  year      = {2007},
  isbn      = {9780511800481},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  biburl    = {https://dblp.org/rec/books/cu/NRTV2007.bib},
  doi       = {10.1017/CBO9780511800481},
}

@Article{Ahmadi2022,
  author        = {Ahmadi, Saba and Beyhaghi, Hedyeh and Blum, Avrim and Naggita, Keziah},
  title         = {Setting Fair Incentives to Maximize Improvement},
  year          = {2022},
  month         = feb,
  abstract      = {We consider the problem of helping agents improve by setting short-term goals. Given a set of target skill levels, we assume each agent will try to improve from their initial skill level to the closest target level within reach or do nothing if no target level is within reach. We consider two models: the common improvement capacity model, where agents have the same limit on how much they can improve, and the individualized improvement capacity model, where agents have individualized limits. Our goal is to optimize the target levels for social welfare and fairness objectives, where social welfare is defined as the total amount of improvement, and fairness objectives are considered where the agents belong to different underlying populations. A key technical challenge of this problem is the non-monotonicity of social welfare in the set of target levels, i.e., adding a new target level may decrease the total amount of improvement as it may get easier for some agents to improve. This is especially challenging when considering multiple groups because optimizing target levels in isolation for each group and outputting the union may result in arbitrarily low improvement for a group, failing the fairness objective. Considering these properties, we provide algorithms for optimal and near-optimal improvement for both social welfare and fairness objectives. These algorithmic results work for both the common and individualized improvement capacity models. Furthermore, we show a placement of target levels exists that is approximately optimal for the social welfare of each group. Unlike the algorithmic results, this structural statement only holds in the common improvement capacity model, and we show counterexamples in the individualized improvement capacity model. Finally, we extend our algorithms to learning settings where we have only sample access to the initial skill levels of agents.},
  archiveprefix = {arXiv},
  copyright     = {arXiv.org perpetual, non-exclusive license},
  doi           = {10.48550/ARXIV.2203.00134},
  eprint        = {2203.00134},
  file          = {:http\://arxiv.org/pdf/2203.00134v1:PDF},
  keywords      = {Computer Science and Game Theory (cs.GT), Machine Learning (cs.LG), Multiagent Systems (cs.MA), FOS: Computer and information sciences},
  primaryclass  = {cs.GT},
  publisher     = {arXiv},
  ranking       = {rank3},
}

@Misc{Shao2023,
  author        = {Han Shao and Lee Cohen and Avrim Blum and Yishay Mansour and Aadirupa Saha and Matthew R. Walter},
  title         = {Eliciting User Preferences for Personalized Multi-Objective Decision Making through Comparative Feedback},
  year          = {2023},
  archiveprefix = {arXiv},
  eprint        = {2302.03805},
  primaryclass  = {cs.LG},
  ranking       = {rank3},
}

@Article{Vazirani2023,
  author        = {Vazirani, Vijay V.},
  title         = {The Investment Management Game: Extending the Scope of the Notion of Core},
  year          = {2023},
  month         = feb,
  abstract      = {The core is a dominant solution concept in economics and cooperative game theory; it is predominantly used for profit, equivalently cost or utility, sharing. This paper demonstrates the versatility of this notion by proposing a completely different use: in a so-called investment management game, which is a game against nature rather than a cooperative game. This game has only one agent whose strategy set is all possible ways of distributing her money among investment firms. The agent wants to pick a strategy such that in each of exponentially many future scenarios, sufficient money is available in the right firms so she can buy an optimal investment for that scenario. Such a strategy constitutes a core imputation under a broad interpretation, though traditional formal framework, of the core. Our game is defined on perfect graphs, since the maximum stable set problem can be solved in polynomial time for such graphs. We completely characterize the core of this game, analogous to Shapley and Shubik characterization of the core of the assignment game. A key difference is the following technical novelty: whereas their characterization follows from total unimodularity, ours follows from total dual integrality},
  archiveprefix = {arXiv},
  copyright     = {Creative Commons Attribution 4.0 International},
  doi           = {10.48550/ARXIV.2302.00608},
  eprint        = {2302.00608},
  file          = {:http\://arxiv.org/pdf/2302.00608v5:PDF},
  keywords      = {Theoretical Economics (econ.TH), Data Structures and Algorithms (cs.DS), Computer Science and Game Theory (cs.GT), FOS: Economics and business, FOS: Computer and information sciences},
  primaryclass  = {econ.TH},
  publisher     = {arXiv},
}

@Conference{Fairstein2022,
  author    = {Fairstein, Roy and Vilenchik, Dan and Meir, Reshef and Gal, Kobi},
  booktitle = {Proceedings of the 21st International Conference on Autonomous Agents and Multiagent Systems},
  title     = {Welfare vs. Representation in Participatory Budgeting},
  year      = {2022},
  address   = {Richland, SC},
  month     = {5},
  pages     = {409–417},
  publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
  series    = {AAMAS '22},
  abstract  = {Participatory budgeting (PB) is a democratic process for allocating funds to projects based on the votes of members of the community. Different rules have been used to aggregate participants' votes.A recent paper by Lackner and Skowron [12] studied the tradeoff between notions of social welfare and representation in the multi-winner voting, which is a special case of participatory budgeting with identical project costs. But there is little understanding of this trade-off in the more general PB setting. This paper provides a theoretical and empirical study of the worst-case guarantees of several common rules to better understand the trade-off between social welfare and representation. We show that many of the guarantees from the multi-winner setting do not generalize to the PB setting, and that the introduction of costs leads to substantially worse guarantees, thereby exacerbating the welfare-representation trade-off. We further study how the requirement of proportionality over voting rules effects the guarantees on social welfare and representation. We study the latter point also empirically, both on real and synthetic datasets. We show that variants of the recently suggested voting rule Rule-X (which satisfies proportionality) do very well in practice both with respect to social welfare and representation.},
  day       = {9},
  isbn      = {9781450392136},
  keywords  = {fairness, participatory budgeting, social choice},
  location  = {Virtual Event, New Zealand},
  pagetotal = {9},
}

@Article{Troebst2024,
  author        = {Thorben Tr{\"{o}}bst and Vijay V. Vazirani},
  journal       = {CoRR},
  title         = {Cardinal-Utility Matching Markets: The Quest for Envy-Freeness, Pareto-Optimality, and Efficient Computability},
  year          = {2024},
  volume        = {abs/2402.08851},
  archiveprefix = {arXiv},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/journals/corr/abs-2402-08851.bib},
  doi           = {10.48550/ARXIV.2402.08851},
  eprint        = {2402.08851},
}

@Article{Vazirani2024,
  author        = {Vijay V. Vazirani},
  journal       = {CoRR},
  title         = {The Assignment Game: New Mechanisms for Equitable Core Imputations},
  year          = {2024},
  volume        = {abs/2402.11437},
  archiveprefix = {arXiv},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/journals/corr/abs-2402-11437.bib},
  doi           = {10.48550/ARXIV.2402.11437},
  eprint        = {2402.11437},
}

@Article{Janes2008,
  author   = {Janes, Holly and Pepe, Margaret S.},
  journal  = {Biometrics},
  title    = {Matching in Studies of Classification Accuracy: Implications for Analysis, Efficiency, and Assessment of Incremental Value},
  year     = {2008},
  number   = {1},
  pages    = {1-9},
  volume   = {64},
  abstract = {Summary.  In case–control studies evaluating the classification accuracy of a marker, controls are often matched to cases with respect to factors associated with the marker and disease status. In contrast with matching in epidemiologic etiology studies, matching in the classification setting has not been rigorously studied. In this article, we consider the implications of matching in terms of the choice of statistical analysis, efficiency, and assessment of the incremental value of the marker over the matching covariates. We find that adjustment for the matching covariates is essential, as unadjusted summaries of classification accuracy can be biased. In many settings, matching is the most efficient covariate-dependent sampling scheme, and we provide an expression for the optimal matching ratio. However, we also show that matching greatly complicates estimation of the incremental value of the marker. We recommend that matching be carefully considered in the context of these findings.},
  doi      = {https://doi.org/10.1111/j.1541-0420.2007.00823.x},
  eprint   = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1541-0420.2007.00823.x},
  keywords = {Case–control, Efficiency, Matching, ROC curve, Sensitivity, Specificity},
  url      = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1541-0420.2007.00823.x},
}

@InProceedings{Hosseini2022,
  author    = {Mojtaba Hosseini and Vijay V. Vazirani},
  booktitle = {13th Innovations in Theoretical Computer Science Conference, {ITCS} 2022, January 31 - February 3, 2022, Berkeley, CA, {USA}},
  title     = {Nash-Bargaining-Based Models for Matching Markets: One-Sided and Two-Sided; Fisher and Arrow-Debreu},
  year      = {2022},
  editor    = {Mark Braverman},
  pages     = {86:1--86:20},
  publisher = {Schloss Dagstuhl - Leibniz-Zentrum f{\"{u}}r Informatik},
  series    = {LIPIcs},
  volume    = {215},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  biburl    = {https://dblp.org/rec/conf/innovations/HosseiniV22.bib},
  doi       = {10.4230/LIPICS.ITCS.2022.86},
  ranking   = {rank5},
}

@Misc{Hosseini2023,
  author        = {Mojtaba Hosseini and Vijay V. Vazirani},
  title         = {Nash-Bargaining-Based Models for Matching Markets: One-Sided and Two-Sided; Fisher and Arrow-Debreu},
  year          = {2023},
  archiveprefix = {arXiv},
  eprint        = {2105.10704},
  primaryclass  = {cs.GT},
}

@InProceedings{Deng2016,
  author    = {Xiaotie Deng and Zhe Feng and Christos H. Papadimitriou},
  booktitle = {Web and Internet Economics - 12th International Conference, {WINE} 2016, Montreal, Canada, December 11-14, 2016, Proceedings},
  title     = {Power-Law Distributions in a Two-Sided Market and Net Neutrality},
  year      = {2016},
  editor    = {Yang Cai and Adrian Vetta},
  pages     = {59--72},
  publisher = {Springer},
  series    = {Lecture Notes in Computer Science},
  volume    = {10123},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  biburl    = {https://dblp.org/rec/conf/wine/DengFP16.bib},
  doi       = {10.1007/978-3-662-54110-4\_5},
  priority  = {prio3},
  url       = {https://doi.org/10.1007/978-3-662-54110-4_5},
}

@Article{Li2023,
  author    = {Mengling Li and Yohanes E. Riyanto and Menghan Xu},
  journal   = {Games Econ. Behav.},
  title     = {Prioritized organ allocation rules under compatibility constraints},
  year      = {2023},
  pages     = {403--427},
  volume    = {141},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  biburl    = {https://dblp.org/rec/journals/geb/LiRX23.bib},
  doi       = {10.1016/J.GEB.2023.07.005},
  priority  = {prio3},
}

@Article{Cao2020,
  author    = {Cangjian Cao and Sherry Xin Li and Tracy Xiao Liu},
  journal   = {Games Econ. Behav.},
  title     = {A gift with thoughtfulness: {A} field experiment on work incentives},
  year      = {2020},
  pages     = {17--42},
  volume    = {124},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  biburl    = {https://dblp.org/rec/journals/geb/CaoLL20.bib},
  doi       = {10.1016/J.GEB.2020.07.014},
  priority  = {prio3},
}

@InProceedings{Li2023a,
  author    = {Ningyuan Li and Yunxuan Ma and Yang Zhao and Zhijian Duan and Yurong Chen and Zhilin Zhang and Jian Xu and Bo Zheng and Xiaotie Deng},
  booktitle = {Proceedings of the 29th {ACM} {SIGKDD} Conference on Knowledge Discovery and Data Mining, {KDD} 2023, Long Beach, CA, USA, August 6-10, 2023},
  title     = {Learning-Based Ad Auction Design with Externalities: The Framework and {A} Matching-Based Approach},
  year      = {2023},
  editor    = {Ambuj K. Singh and Yizhou Sun and Leman Akoglu and Dimitrios Gunopulos and Xifeng Yan and Ravi Kumar and Fatma Ozcan and Jieping Ye},
  pages     = {1291--1302},
  publisher = {{ACM}},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  biburl    = {https://dblp.org/rec/conf/kdd/LiMZ00ZXZD23.bib},
  doi       = {10.1145/3580305.3599403},
  priority  = {prio3},
  timestamp = {Mon, 25 Sep 2023 08:29:22 +0200},
  url       = {https://doi.org/10.1145/3580305.3599403},
}

@Article{Cheng2023,
  author    = {Yukun Cheng and Xiaotie Deng and Qi Qi and Xiang Yan},
  journal   = {Math. Oper. Res.},
  title     = {Truthfulness of a Network Resource-Sharing Protocol},
  year      = {2023},
  number    = {3},
  pages     = {1522--1552},
  volume    = {48},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  biburl    = {https://dblp.org/rec/journals/mor/ChengDQY23.bib},
  doi       = {10.1287/MOOR.2022.1310},
  priority  = {prio3},
  timestamp = {Fri, 18 Aug 2023 08:46:00 +0200},
  url       = {https://doi.org/10.1287/moor.2022.1310},
}

@Article{Gangam2023,
  author        = {Gangam, Rohith Reddy and Mai, Tung and Raju, Nitya and Vazirani, Vijay V.},
  title         = {The Stable Matching Lattice under Changed Preferences, and Associated Algorithms},
  year          = {2023},
  month         = apr,
  abstract      = {[MV18] introduced a fundamental new algorithmic question on stable matching, namely finding a matching that is stable under two ``nearby'' instances, where ``nearby'' meant that in going from instance $A$ to $B$, only one agent changes its preference list. By first establishing a sequence of structural results on the lattices of $A$ and $B$, [MV18] and [GMRV22] settled all algorithmic questions related to this case. The current paper essentially settles the general case. Assume that instance $B$ is obtained from $A$, both on $n$ workers and $n$ firms, via changes in the preferences of $p$ workers and $q$ firms. If so, we will denote the change by $(p, q)$. Thus [MV18] and [GMRV22] settled the case $(0, 1)$, since they adopt the convention that one firm changes its preferences. Let $\mathcal{M}_A$ and $\mathcal{M}_B$ be the sets of stable matchings of instances $A$ and $B$, and let $\mathcal{L}_A$ and $\mathcal{L}_B$ be their lattices. Our results are: 1. For $(0, n)$, $\mathcal{M}_A \cap \mathcal{M}_B$ is a sublattice of $\mathcal{L}_A$ and of $\mathcal{L}_B$. We can efficiently obtain the worker-optimal and firm-optimal stable matchings in $\mathcal{M}_A \cap \mathcal{M}_B$. We also obtain the associated partial order, as promised by Birkhoff's Representation Theorem, and use it to enumerate these matchings with polynomial delay. 2. For $(1, n)$, the only missing results are the partial order and enumeration. 3. We give an example with $(2, 2)$ for which $\mathcal{M}_A \cap \mathcal{M}_B$ fails to be a sublattice of $\mathcal{L}_A$. In light of the fact that for $(n, n)$, determining if $(\mathcal{M}_A \cap \mathcal{M}_B) = \emptyset$ is NP-hard [MO19], a number of open questions arise; in particular, closing the gap between $(2, 2)$ and $(n, n)$.},
  archiveprefix = {arXiv},
  copyright     = {Creative Commons Attribution 4.0 International},
  doi           = {10.48550/ARXIV.2304.02590},
  eprint        = {2304.02590},
  file          = {:http\://arxiv.org/pdf/2304.02590v2:PDF},
  keywords      = {Discrete Mathematics (cs.DM), FOS: Computer and information sciences},
  primaryclass  = {cs.DM},
  publisher     = {arXiv},
}

@Book{Echenique2023,
  author    = {Echenique, Federico and Immorlica, Nicole and Vazirani, Vijay V.},
  publisher = {Cambridge University Press,},
  title     = {Online and matching-based market design},
  year      = {2023},
  isbn      = {9781108937535},
  month     = may,
  note      = {edited by Federico Echenique, Nicole Immorlica, Vijay V. Vazirani ; with a foreword by Alvin E. Roth. illustrations (black and white), digital, PDF file(s) Specialized. Also issued in print: 2023. Includes bibliographical references and index. Description based on online resource; title from PDF title page},
  abstract  = {Written by more than fifty top researchers from economics, OR, and algorithm design, this text comprehensively covers a major inter-disciplinary field and its important applications from the basics to state of the art. Key chapters discuss efficiency, fairness and incentives, and market design and its relation to social choice theory.},
  doi       = {10.1017/9781108937535},
  keywords  = {Economics Mathematical models. Commerce Mathematical models. Operations research. Matching theory. Algorithms Design.},
  pages     = {1 online resource (xxii, 697 pages)},
  type      = {Electronic Book},
  url       = {https://yale.idm.oclc.org/login?URL=https://doi.org/10.1017/9781108937535},
}

@Article{Ahani2024,
  author     = {Ahani, Narges and G\"{o}lz, Paul and Procaccia, Ariel D. and Teytelboym, Alexander and Trapp, Andrew C.},
  journal    = {Commun. ACM},
  title      = {Dynamic Placement in Refugee Resettlement},
  year       = {2024},
  issn       = {0001-0782},
  month      = {may},
  number     = {5},
  pages      = {99–106},
  volume     = {67},
  abstract   = {Employment outcomes of resettled refugees depend strongly on where they are placed inside the host country. While the U.S. sets refugee capacities for communities on an annual basis, refugees arrive and must be placed over the course of the year. We introduce a dynamic allocation system based on potentials derived from dual prices of a linear programming (LP) relaxation to improve employment outcomes. Our algorithm achieves over 98\% of the hindsight- optimal employment compared to under 90\% of current greedy-like approaches. This dramatic improvement persists even when we incorporate a vast array of practical features of the refugee resettlement process including indivisible families, batching, and uncertainty with respect to the number of future arrivals. Our algorithm is now part of the Annie™ Moore optimization software used by a leading American refugee resettlement agency.},
  address    = {New York, NY, USA},
  doi        = {10.1145/3611073},
  issue_date = {May 2024},
  numpages   = {8},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/3611073},
}

@Article{Freund2024,
  author     = {Freund, Daniel},
  journal    = {Commun. ACM},
  title      = {Improving Refugees' Integration with Online Resource Allocation: Technical Perspective},
  year       = {2024},
  issn       = {0001-0782},
  month      = {may},
  number     = {5},
  pages      = {9898},
  volume     = {67},
  address    = {New York, NY, USA},
  doi        = {10.1145/3639539},
  issue_date = {May 2024},
  numpages   = {1},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/3639539},
}

@InProceedings{Goemans2005,
  author    = {Goemans, M. and Mirrokni, V. and Vetta, A.},
  booktitle = {46th Annual IEEE Symposium on Foundations of Computer Science (FOCS’05)},
  title     = {Sink Equilibria and Convergence},
  year      = {2005},
  pages     = {142-151},
  publisher = {IEEE},
  doi       = {10.1109/sfcs.2005.68},
  keywords  = {Convergence;Routing;Cost function;Steady-state;Polynomials;Delay;Performance analysis;Control systems;Nash equilibrium;Computer science},
  ranking   = {rank5},
}

@InProceedings{Konda2023,
  author    = {Konda, Rohit and Chandan, Rahul and Marden, Jason R.},
  booktitle = {2023 62nd IEEE Conference on Decision and Control (CDC)},
  title     = {Quality of Non-Convergent Best Response Processes in Multi-Agent Systems through Sink Equilibria},
  year      = {2023},
  pages     = {6996-7001},
  doi       = {10.1109/CDC49753.2023.10383372},
  keywords  = {Measurement;Limiting;Games;Predictive models;Nash equilibrium;Linear programming;Behavioral sciences},
}






@Article{Balcan2013,
  author    = {Balcan, Maria-Florina and Blum, Avrim and Mansour, Yishay},
  journal   = {SIAM Journal on Computing},
  title     = {Circumventing the Price of Anarchy: Leading Dynamics to Good Behavior},
  year      = {2013},
  number    = {1},
  pages     = {230-264},
  volume    = {42},
  abstract  = {Many natural games have a dramatic difference between the quality of their best and worst Nash equilibria, even in pure strategies. Yet, nearly all results to date on dynamics in games show only convergence to some equilibrium, especially within a polynomial number of steps. In this work we initiate a theory of how well-motivated multiagent dynamics can make use of global information about the game---which might be common knowledge or injected into the system by a helpful central agency---and show that in a wide range of interesting games this can allow the dynamics to quickly reach (within a polynomial number of steps) states of cost comparable to the best Nash equilibrium. We present several natural models for dynamics that can use such additional information and analyze their ability to reach low-cost states for two important and widely studied classes of potential games: network design with fair cost-sharing and party affiliation games (which include consensus and cut games). From the perspective of a central agency, our work can be viewed as analyzing how a public service advertising campaign can help “nudge” behavior into a good state, when players cannot be expected to all blindly follow along but instead view the information as an additional input into their dynamics. We show that in many cases, this additional information is sufficient for natural dynamics to quickly reach states of cost comparable to the best Nash equilibrium of the game.},
  doi       = {10.1137/110821317},
  eprint    = {https://doi.org/10.1137/110821317},
  printed   = {printed},
  ranking   = {rank5},
  relevance = {relevant},
  url       = {https://doi.org/10.1137/110821317},
}

@Article{Yamaguchi2015,
  author   = {Yamaguchi, Yutaro and Ogawa, Anna and Takeda, Akiko and Iwata, Satoru},
  journal  = {IEEE Transactions on Smart Grid},
  title    = {Cyber Security Analysis of Power Networks by Hypergraph Cut Algorithms},
  year     = {2015},
  number   = {5},
  pages    = {2189-2199},
  volume   = {6},
  doi      = {10.1109/TSG.2015.2394791},
  keywords = {Indexes;Vectors;Computer security;Power measurement;Algorithm design and analysis;Power systems;False data injection;hypergraph;minimum cut;power network;security index;state estimation;False data injection;hypergraph;minimum cut;power network;security index;state estimation},
  ranking  = {rank3},
}

@InProceedings{Hakim2024,
  author    = {Hakim, Rashida and Milionis, Jason and Papadimitriou, Christos and Piliouras, Georgios},
  booktitle = {Algorithmic Game Theory},
  title     = {Swim till You Sink: Computing the Limit of a Game},
  year      = {2024},
  address   = {Cham},
  editor    = {Sch{\"a}fer, Guido and Ventre, Carmine},
  pages     = {205--222},
  publisher = {Springer Nature Switzerland},
  abstract  = {During 2023, two interesting results were proven about the limit behavior of game dynamics: First, it was shown that there is a game for which no dynamics converges to the Nash equilibria. Second, it was shown that the sink equilibria of a game adequately capture the limit behavior of natural game dynamics. These two results have created a need and opportunity to articulate a principled computational theory of the meaning of the game that is based on game dynamics. Given any game in normal form, and any prior distribution of play, we study the problem of computing the asymptotic behavior of a class of natural dynamics called the noisy replicator dynamics as a limit distribution over the sink equilibria of the game. When the prior distribution has pure strategy support, we prove this distribution can be computed efficiently, in near-linear time to the size of the best-response graph. When the distribution can be sampled---for example, if it is the uniform distribution over all mixed strategy profiles---we show through experiments that the limit distribution of reasonably large games can be estimated quite accurately through sampling and simulation.},
  groups    = {ideas},
  isbn      = {978-3-031-71033-9},
  ranking   = {rank3},
}

@Article{Omidshafiei2019,
  author   = {Omidshafiei, Shayegan and Papadimitriou, Christos and Piliouras, Georgios and Tuyls, Karl and Rowland, Mark and Lespiau, Jean-Baptiste and Czarnecki, Wojciech M. and Lanctot, Marc and Perolat, Julien and Munos, Remi},
  journal  = {Scientific Reports},
  title    = {α-Rank: Multi-Agent Evaluation by Evolution},
  year     = {2019},
  issn     = {2045-2322},
  number   = {1},
  pages    = {9937},
  volume   = {9},
  abstract = {We introduce α-Rank, a principled evolutionary dynamics methodology, for the evaluation and ranking of agents in large-scale multi-agent interactions, grounded in a novel dynamical game-theoretic solution concept called Markov-Conley chains (MCCs). The approach leverages continuous-time and discrete-time evolutionary dynamical systems applied to empirical games, and scales tractably in the number of agents, in the type of interactions (beyond dyadic), and the type of empirical games (symmetric and asymmetric). Current models are fundamentally limited in one or more of these dimensions, and are not guaranteed to converge to the desired game-theoretic solution concept (typically the Nash equilibrium). α-Rank automatically provides a ranking over the set of agents under evaluation and provides insights into their strengths, weaknesses, and long-term dynamics in terms of basins of attraction and sink components. This is a direct consequence of the correspondence we establish to the dynamical MCC solution concept when the underlying evolutionary model’s ranking-intensity parameter, α, is chosen to be large, which exactly forms the basis of α-Rank. In contrast to the Nash equilibrium, which is a static solution concept based solely on fixed points, MCCs are a dynamical solution concept based on the Markov chain formalism, Conley’s Fundamental Theorem of Dynamical Systems, and the core ingredients of dynamical systems: fixed points, recurrent sets, periodic orbits, and limit cycles. Our α-Rank method runs in polynomial time with respect to the total number of pure strategy profiles, whereas computing a Nash equilibrium for a general-sum game is known to be intractable. We introduce mathematical proofs that not only provide an overarching and unifying perspective of existing continuous- and discrete-time evolutionary evaluation models, but also reveal the formal underpinnings of the α-Rank methodology. We illustrate the method in canonical games and empirically validate it in several domains, including AlphaGo, AlphaZero, MuJoCo Soccer, and Poker.},
  doi      = {10.1038/s41598-019-45619-9},
  refid    = {Omidshafiei2019},
  url      = {https://doi.org/10.1038/s41598-019-45619-9},
}

@Article{Yin2023,
  author   = {Yin, Qi-Yue and Yang, Jun and Huang, Kai-Qi and Zhao, Mei-Jing and Ni, Wan-Cheng and Liang, Bin and Huang, Yan and Wu, Shu and Wang, Liang},
  journal  = {Machine Intelligence Research},
  title    = {AI in Human-computer Gaming: Techniques, Challenges and Opportunities},
  year     = {2023},
  issn     = {2731-5398},
  number   = {3},
  pages    = {299--317},
  volume   = {20},
  abstract = {With the breakthrough of AlphaGo, human-computer gaming AI has ushered in a big explosion, attracting more and more researchers all over the world. As a recognized standard for testing artificial intelligence, various human-computer gaming AI systems (AIs) have been developed, such as Libratus, OpenAI Five, and AlphaStar, which beat professional human players. The rapid development of human-computer gaming AIs indicates a big step for decision-making intelligence, and it seems that current techniques can handle very complex human-computer games. So, one natural question arises: What are the possible challenges of current techniques in human-computer gaming and what are the future trends? To answer the above question, in this paper, we survey recent successful game AIs, covering board game AIs, card game AIs, first-person shooting game AIs, and real-time strategy game AIs. Through this survey, we 1) compare the main difficulties among different kinds of games and the corresponding techniques utilized for achieving professional human-level AIs; 2) summarize the mainstream frameworks and techniques that can be properly relied on for developing AIs for complex human-computer games; 3) raise the challenges or drawbacks of current techniques in the successful AIs; and 4) try to point out future trends in human-computer gaming AIs. Finally, we hope that this brief review can provide an introduction for beginners and inspire insight for researchers in the field of AI in human-computer gaming.},
  doi      = {10.1007/s11633-022-1384-6},
  refid    = {Yin2023},
  url      = {https://doi.org/10.1007/s11633-022-1384-6},
}

@Article{Li2024,
  author   = {Li, Xiuxian and Meng, Min and Hong, Yiguang and Chen, Jie},
  journal  = {Science China Information Sciences},
  title    = {A survey of decision making in adversarial games},
  year     = {2024},
  issn     = {1869-1919},
  number   = {4},
  pages    = {141201},
  volume   = {67},
  abstract = {In many practical applications, such as poker, chess, drug interdiction, cybersecurity, and national defense, players often have adversarial stances, i.e., the selfish actions of each player inevitably or intentionally inflict loss or wreak havoc on other players. Therefore, adversarial games are important in real-world applications. However, only special adversarial games, such as Bayesian games, are reviewed in the literature. In this respect, this study aims to provide a systematic survey of three main game models widely employed in adversarial games, i.e., zero-sum normal-form and extensive-form games, Stackelberg (security) games, and zero-sum differential games, from an array of perspectives, including basic knowledge of game models, (approximate) equilibrium concepts, problem classifications, research frontiers, (approximate) optimal strategy-seeking techniques, prevailing algorithms, and practical applications. Finally, promising future research directions are also discussed for relevant adversarial games.},
  doi      = {10.1007/s11432-022-3777-y},
  refid    = {Li2024},
  url      = {https://doi.org/10.1007/s11432-022-3777-y},
}

@Article{Qin2024,
  author   = {Qin, Rong-Jun and Yu, Yang},
  journal  = {Science China Information Sciences},
  title    = {Learning in games: a systematic review},
  year     = {2024},
  issn     = {1869-1919},
  number   = {7},
  pages    = {171101},
  volume   = {67},
  abstract = {Game theory studies the mathematical models for self-interested individuals. Nash equilibrium is arguably the most central solution in game theory. While finding the Nash equilibrium in general is known as polynomial parity arguments on directed graphs (PPAD)-complete, learning in games provides an alternative to approximate Nash equilibrium, which iteratively updates the player’s strategy through interactions with other players. Rules and models have been developed for learning in games, such as fictitious play and no-regret learning. Particularly, with recent advances in online learning and deep reinforcement learning, techniques from these fields greatly boost the breakthroughs in learning in games from theory to application. As a result, we have witnessed many superhuman game AI systems. The techniques used in these systems evolve from conventional search and learning to purely reinforcement learning (RL)-style learning methods, gradually getting rid of the domain knowledge. In this article, we systematically review the above techniques, discuss the trend of basic learning rules towards a unified framework, and recap applications in large games. Finally, we discuss some future directions and make the prospect of future game AI systems. We hope this article will give some insights into designing novel approaches.},
  doi      = {10.1007/s11432-023-3955-x},
  refid    = {Qin2024},
  url      = {https://doi.org/10.1007/s11432-023-3955-x},
}






@InBook{Goemans,
  author    = {Michel X. Goemans and Nicholas J. A. Harvey and Satoru Iwata and Vahab Mirrokni},
  pages     = {535-544},
  title     = {Approximating Submodular Functions Everywhere},
  year      = {2009},
  abstract  = {Abstract Submodular functions are a key concept in combinatorial optimization. Algorithms that involve submodular functions usually assume that they are given by a (value) oracle. Many interesting problems involving submodular functions can be solved using only polynomially many queries to the oracle, e.g., exact minimization or approximate maximization. In this paper, we consider the problem of approximating a non-negative, monotone, submodular function f on a ground set of size n everywhere, after only poly(n) oracle queries. Our main result is a deterministic algorithm that makes poly(n) oracle queries and derives a function such that, for every set S, (S) approximates f(S) within a factor α(n), where for rank functions of matroids and for general monotone submodular functions. Our result is based on approximately finding a maximum volume inscribed ellipsoid in a symmetrized polymatroid, and the analysis involves various properties of submodular functions and polymatroids. Our algorithm is tight up to logarithmic factors. Indeed, we show that no algorithm can achieve a factor better than , even for rank functions of a matroid.},
  booktitle = {Proceedings of the 2009 Annual ACM-SIAM Symposium on Discrete Algorithms (SODA)},
  doi       = {10.1137/1.9781611973068.59},
  eprint    = {https://epubs.siam.org/doi/pdf/10.1137/1.9781611973068.59},
  url       = {https://epubs.siam.org/doi/abs/10.1137/1.9781611973068.59},
}






@InBook{Bamas,
  author    = {Étienne Bamas and Alexander Lindermayr and Nicole Megow and Lars Rohwedder and Jens Schlöter},
  pages     = {2829-2860},
  title     = {Santa Claus meets Makespan and Matroids: Algorithms and Reductions},
  year      = {2024},
  abstract  = {Abstract In this paper we study the relation of two fundamental problems in scheduling and fair allocation: makespan minimization on unrelated parallel machines and max-min fair allocation, also known as the Santa Claus problem. For both of these problems the best approximation factor is a notorious open question; more precisely, whether there is a better-than-2 approximation for the former problem and whether there is a constant approximation for the latter. While the two problems are intuitively related and history has shown that techniques can often be transferred between them, no formal reductions are known. We first show that an affirmative answer to the open question for makespan minimization implies the same for the Santa Claus problem by reducing the latter problem to the former. We also prove that for problem instances with only two input values both questions are equivalent. We then move to a special case called “restricted assignment”, which is well studied in both problems. Although our reductions do not maintain the characteristics of this special case, we give a reduction in a slight generalization, where the jobs or resources are assigned to multiple machines or players subject to a matroid constraint and in addition we have only two values. Since for the Santa Claus problem with matroids the two value case is up to constants equivalent to the general case, this draws a similar picture as before: equivalence for two values and the general case of Santa Claus can only be easier than makespan minimization. To complete the picture, we give an algorithm for our new matroid variant of the Santa Claus problem using a non-trivial extension of the local search method from restricted assignment. Thereby we unify, generalize, and improve several previous results. We believe that this matroid generalization may be of independent interest and provide several sample applications. As corollaries, we obtain a polynomial-time (2 — 1/nɛ)-approximation for two-value makespan minimization for every ɛ > 0, improving on the previous (2 — 1/m)-approximation, and a polynomial-time (1.75 + ɛ)- approximation for makespan minimization in the restricted assignment case with two values, improving the previous best rate of . * We thank Schloss Dagstuhl for hosting the Seminar 23061 on Scheduling in February 2023 where we had fruitful discussions on this topic.},
  booktitle = {Proceedings of the 2024 Annual ACM-SIAM Symposium on Discrete Algorithms (SODA)},
  doi       = {10.1137/1.9781611977912.100},
  eprint    = {https://epubs.siam.org/doi/pdf/10.1137/1.9781611977912.100},
  ranking   = {rank5},
  url       = {https://epubs.siam.org/doi/abs/10.1137/1.9781611977912.100},
}






@InBook{Izumi,
  author    = {Taisuke Izumi and Naoki Kitamura and Yutaro Yamaguchi},
  pages     = {4062-4082},
  title     = {A Nearly Linear-Time Distributed Algorithm for Exact Maximum Matching},
  year      = {2024},
  abstract  = {Abstract In this paper, we propose a randomized Õ(µ(G))-round algorithm for the maximum cardinality matching problem in the CONGEST model, where µ(G) means the maximum size of a matching of the input graph G. The proposed algorithm substantially improves the current best worst-case running time. The key technical ingredient is a new randomized algorithm of finding an augmenting path of length ℓ with high probability within Õ(ℓ) rounds, which positively settles an open problem left in the prior work by Ahmadi and Kuhn [DISC’20]. The idea of our augmenting path algorithm is based on a recent result by Kitamura and Izumi [IEICE Trans.’22], which efficiently identifies a sparse substructure of the input graph containing an augmenting path, following a new concept called alternating base trees. Their algorithm, however, resorts to a centralized approach of collecting the entire information of the substructure into a single vertex for constructing an augmenting path. The technical highlight of this paper is to provide a fully-decentralized counterpart of such a centralized method. To develop the algorithm, we prove several new structural properties of alternating base trees, which are of independent interest.},
  booktitle = {Proceedings of the 2024 Annual ACM-SIAM Symposium on Discrete Algorithms (SODA)},
  doi       = {10.1137/1.9781611977912.141},
  eprint    = {https://epubs.siam.org/doi/pdf/10.1137/1.9781611977912.141},
  url       = {https://epubs.siam.org/doi/abs/10.1137/1.9781611977912.141},
}






@InBook{Chuzhoy,
  author    = {Julia Chuzhoy and Sanjeev Khanna},
  pages     = {2185-2235},
  title     = {A Faster Combinatorial Algorithm for Maximum Bipartite Matching},
  year      = {2024},
  abstract  = {Abstract The maximum bipartite matching problem is among the most fundamental and well-studied problems in combinatorial optimization. A beautiful and celebrated combinatorial algorithm of Hopcroft and Karp [26] shows that maximum bipartite matching can be solved in O(m√n) time on a graph with n vertices and m edges. For the case of very dense graphs, a different approach based on fast matrix multiplication was subsequently developed [27, 39], that achieves a running time of O(n2.371). For the next several decades, these results represented the fastest known algorithms for the problem until in 2013, a ground-breaking work of Madry [36] gave a significantly faster algorithm for sparse graphs. Subsequently, a sequence of works developed increasingly faster algorithms for solving maximum bipartite matching, and more generally directed maximum flow, culminating in a spectacular recent breakthrough [9] that gives an m1+o(1) time algorithm for maximum bipartite matching (and more generally, for min cost flows). These more recent developments collectively represented a departure from earlier combinatorial approaches: they all utilized continuous techniques based on interior-point methods for solving linear programs. This raises a natural question: are continuous techniques essential to obtaining fast algorithms for the bipartite matching problem? Our work makes progress on this question by presenting a new, purely combinatorial algorithm for bipartite matching, that, on moderately dense graphs outperforms both Hopcroft- Karp and the fast matrix multiplication based algorithms. Similar to the classical algorithms for bipartite matching, our approach is based on iteratively augmenting a current matching using augmenting paths in the (directed) residual flow network. A common method for designing fast algorithms for directed flow problems is via the multiplicative weights update (MWU) framework, that effectively reduces the flow problem to decremental single-source shortest paths (SSSP) in directed graphs. Our main observation is that a slight modification of this reduction results in a special case of SSSP that appears significantly easier than general decremental directed SSSP. Our main technical contribution is an efficient algorithm for this special case of SSSP, that outperforms the current state of the art algorithms for general decremental SSSP with adaptive adversary, leading to a deterministic algorithm for bipartite matching, whose running time is Õ(m1/3n5/3). This new algorithm thus starts to outperform the Hopcroft-Karp algorithm in graphs with m = ω(n7/4), and it also outperforms the fast matrix multiplication based algorithms on dense graphs. We believe that this framework for obtaining faster combinatorial algorithms for bipartite matching by exploiting the special properties of the resulting decremental SSSP instances is one of the main conceptual contributions of our work that we hope paves the way for even faster combinatorial algorithms for bipartite matching. Finally, using a standard reduction from the maximum vertex-capacitated s-t flow problem in directed graphs to maximum bipartite matching, we also obtain an O(m1/3n5/3) time deterministic algorithm for maximum vertex-capacitated s-t flow when all vertex capacities are identical.},
  booktitle = {Proceedings of the 2024 Annual ACM-SIAM Symposium on Discrete Algorithms (SODA)},
  doi       = {10.1137/1.9781611977912.79},
  eprint    = {https://epubs.siam.org/doi/pdf/10.1137/1.9781611977912.79},
  url       = {https://epubs.siam.org/doi/abs/10.1137/1.9781611977912.79},
}






@InBook{Brown,
  author    = {Adam Brown and Aditi Laddha and Madhusudhan Reddy Pittu and Mohit Singh},
  pages     = {1307-1327},
  title     = {Approximation Algorithms for the Weighted Nash Social Welfare via Convex and Non-Convex Programs},
  year      = {2024},
  abstract  = {Abstract In an instance of the weighted Nash Social Welfare problem, we are given a set of m indivisible items, G, and n agents, A, where each agent i ∈ A has a valuation vij ≥ 0 for each item j ∈ G. In addition, every agent i has a non-negative weight wi such that the weights collectively sum up to 1. The goal is to find an assignment σ : G → A that maximizes . When all the weights equal to , the problem reduces to the classical Nash Social Welfare problem, which has recently received much attention. In this work, we present a -approximation algorithm for the weighted Nash Social Welfare problem, where denotes the KL-divergence between the distribution w and the uniform distribution on [n]. We generalize the convex programming relaxations for the symmetric variant of Nash Social Welfare presented in [CDG+17, AGSS17] to two different mathematical programs. The first program is convex and is necessary for computational efficiency, while the second program is a non-convex relaxation that can be rounded efficiently. The approximation factor derives from the difference in the objective values of the convex and non-convex relaxation.},
  booktitle = {Proceedings of the 2024 Annual ACM-SIAM Symposium on Discrete Algorithms (SODA)},
  doi       = {10.1137/1.9781611977912.52},
  eprint    = {https://epubs.siam.org/doi/pdf/10.1137/1.9781611977912.52},
  url       = {https://epubs.siam.org/doi/abs/10.1137/1.9781611977912.52},
}






@InBook{Correa,
  author    = {José Correa and Tobias Harks and Anja Schedel and José Verschae},
  pages     = {547-568},
  title     = {Equilibrium Dynamics in Market Games with Exchangeable and Divisible Resources},
  year      = {2024},
  abstract  = {Abstract We study a market game with n ≥ 2 players competing over m ≥ 1 divisible resources of different finite capacities. Resources are traded via the proportional sharing mechanism, where players are price-anticipating, meaning that they can influence the prices with their bids. Additionally, each player has an initial endowment of the resources which are sold at market prices. Although the players’ total profit functions may be discontinuous in the bids, we prove existence and uniqueness of pure Nash equilibria of the resulting market game. Then, we study a discrete dynamic arising from repeatedly taking the (unique) equilibrium resource allocation as initial endowments for the next market game. We prove that the total utility value of the dynamic converges to either an optimal allocation value (maximizing total utility over the allocation space) or to a restricted optimal allocation value, where the restriction is defined by fixing some tight resources which are exclusively allocated to a single player. As a corollary, it follows that for strictly concave utility functions, the aggregated allocation vector of the dynamic converges to the unique (possibly restricted) optimal aggregated allocation, and for linear utility functions, we even get convergence of the dynamic to a (possibly restricted) optimal solution in the (non-aggregated) original allocation space. * This manuscript was partially funded by Basal CMM FB210005 and by the Deutsche Forschungsgemeinschaft (DFG, German Research Foundation)—HA 8041/4-1. We are grateful to the anonymous reviewers for their valuable feedback on this paper.},
  booktitle = {Proceedings of the 2024 Annual ACM-SIAM Symposium on Discrete Algorithms (SODA)},
  doi       = {10.1137/1.9781611977912.20},
  eprint    = {https://epubs.siam.org/doi/pdf/10.1137/1.9781611977912.20},
  url       = {https://epubs.siam.org/doi/abs/10.1137/1.9781611977912.20},
}






@InBook{Gorantla,
  author    = {Pranay Gorantla and Kunal Marwaha and Santhoshini Velusamy},
  pages     = {304-331},
  title     = {Fair allocation of a multiset of indivisible items},
  year      = {2023},
  abstract  = {We study the problem of fairly allocating a multiset M of m indivisible items among n agents with additive valuations. Specifically, we introduce a parameter t for the number of distinct types of items and study fair allocations of multisets that contain only items of these t types, under two standard notions of fairness: 1. Envy-freeness (EF): For arbitrary n, t, we show that a complete EF allocation exists when at least one agent has a unique valuation and the number of items of each type exceeds a particular finite threshold. We give explicit upper and lower bounds on this threshold in some special cases. 2. Envy-freeness up to any good (EFX): For arbitrary n, m, and for t ≤ 2, we show that a complete EFX allocation always exists. We give two different proofs of this result. One proof is constructive and runs in polynomial time; the other is geometrically inspired.},
  booktitle = {Proceedings of the 2023 Annual ACM-SIAM Symposium on Discrete Algorithms (SODA)},
  doi       = {10.1137/1.9781611977554.ch13},
  eprint    = {https://epubs.siam.org/doi/pdf/10.1137/1.9781611977554.ch13},
  url       = {https://epubs.siam.org/doi/abs/10.1137/1.9781611977554.ch13},
}

@InProceedings{Garg2022,
  author    = {Jugal Garg and Yixin Tao and L{\'{a}}szl{\'{o}} A. V{\'{e}}gh},
  booktitle = {Proceedings of the 2022 {ACM-SIAM} Symposium on Discrete Algorithms, {SODA} 2022, Virtual Conference / Alexandria, VA, USA, January 9 - 12, 2022},
  title     = {Approximating Equilibrium under Constrained Piecewise Linear Concave Utilities with Applications to Matching Markets},
  year      = {2022},
  editor    = {Joseph (Seffi) Naor and Niv Buchbinder},
  pages     = {2269--2284},
  publisher = {{SIAM}},
  abstract  = {We study the equilibrium computation problem in the Fisher market model with constrained piecewise linear concave (PLC) utilities. This general class captures many well-studied special cases, including markets with PLC utilities, markets with satiation, and matching markets. For the special case of PLC utilities, although the problem is PPAD-hard, Devanur and Kannan (FOCS 2008) gave a polynomial-time algorithm when the number of goods is constant. Our main result is a fixed parameter approximation scheme for computing an approximate equilibrium, where the parameters are the number of agents and the approximation accuracy. This provides an answer to an open question by Devanur and Kannan for PLC utilities, and gives a simpler and faster algorithm for matching markets as the one by Alaei, Jalaly and Tardos (EC 2017). The main technical idea is to work with the stronger concept of thrifty equilibria, and approximating the input utility functions by ‘robust’ utilities that have favorable marginal properties. With some restrictions, the results also extend to the Arrow–Debreu exchange market model.},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  biburl    = {https://dblp.org/rec/conf/soda/GargTV22.bib},
  doi       = {10.1137/1.9781611977073.91},
  eprint    = {https://epubs.siam.org/doi/pdf/10.1137/1.9781611977073.91},
  priority  = {prio3},
  url       = {https://epubs.siam.org/doi/abs/10.1137/1.9781611977073.91},
}






@InBook{Kavitha,
  author    = {Telikepalli Kavitha and Tamás Király and Jannik Matuschke and Ildikó Schlotter and Ulrike Schmidt-Kraepelin},
  pages     = {103-123},
  title     = {The popular assignment problem: when cardinality is more important than popularity},
  year      = {2022},
  abstract  = {We consider a matching problem in a bipartite graph G = (A∪B, E) where each node in A is an agent having preferences in partial order over her neighbors, while nodes in B are objects with no preferences. The size of our matching is more important than node preferences–thus, we are interested in maximum matchings only. Any pair of maximum matchings in G (equivalently, perfect matchings or assignments) can be compared by holding a head-to-head election between them where agents are voters. The goal is to compute an assignment such that there is no better or “more popular” assignment. This is the popular assignment problem and it generalizes the well-studied popular matching problem (Abraham et al., 2007). Popular assignments need not exist in every input instance. We show a polynomial-time algorithm that decides if the given instance admits one or not, and computes one, if so. In instances with no popular assignment, we consider the problem of finding an almost popular assignment, i.e., an assignment with minimum unpopularity margin. We show an O∗ (|E|k) time algorithm for deciding if there exists an assignment with unpopularity margin at most k. We then show that this algorithm is essentially optimal by proving that the problem is NP-complete and Wl[1]-hard with parameter k. We also consider the minimum-cost popular assignment problem when there are edge costs, and show this problem to be NP-hard. This hardness holds even when all edge costs are in {0,1} and agents have strict preferences. By contrast, we propose a polynomial-time algorithm to the problem of deciding if there exists a popular assignment with a given set of forced/forbidden edges (this tractability holds even for partially ordered preferences). Our algorithms are combinatorial and based on LP duality. They search for an appropriate witness or dual certificate, and when a certificate cannot be found, we prove that the desired assignment does not exist in G.},
  booktitle = {Proceedings of the 2022 Annual ACM-SIAM Symposium on Discrete Algorithms (SODA)},
  doi       = {10.1137/1.9781611977073.6},
  eprint    = {https://epubs.siam.org/doi/pdf/10.1137/1.9781611977073.6},
  url       = {https://epubs.siam.org/doi/abs/10.1137/1.9781611977073.6},
}






@InBook{Banerjee,
  author    = {Siddhartha Banerjee and Vasilis Gkatzelis and Artur Gorokh and Billy Jin},
  pages     = {1-19},
  title     = {Online Nash Social Welfare Maximization with Predictions},
  year      = {2022},
  abstract  = {We consider the problem of allocating a set of divisible goods to N agents in an online manner, aiming to maximize the Nash social welfare, a widely studied objective which provides a balance between fairness and efficiency. The goods arrive in a sequence of T periods and the value of each agent for a good is adversarially chosen when the good arrives. We first observe that no online algorithm can achieve a competitive ratio better than the trivial O(N), unless it is given additional information about the agents' values. Then, in line with the emerging area of “algorithms with predictions”, we consider a setting where for each agent, the online algorithm is only given a prediction of her monopolist utility, i.e., her utility if all goods were given to her alone (corresponding to the sum of her values over the T periods). Our main result is an online algorithm whose competitive ratio is parameterized by the multiplicative errors in these predictions. The algorithm achieves a competitive ratio of O(log N) and O(log T) if the predictions are perfectly accurate. Moreover, the competitive ratio degrades smoothly with the errors in the predictions, and is surprisingly robust: the logarithmic competitive ratio holds even if the predictions are very inaccurate. We complement this positive result by showing that our bounds are essentially tight: no online algorithm, even if provided with perfectly accurate predictions, can achieve a competitive ratio of O(log1–∊ N) or O(log1–∊ T) for any constant ∊ > 0.},
  booktitle = {Proceedings of the 2022 Annual ACM-SIAM Symposium on Discrete Algorithms (SODA)},
  doi       = {10.1137/1.9781611977073.1},
  eprint    = {https://epubs.siam.org/doi/pdf/10.1137/1.9781611977073.1},
  url       = {https://epubs.siam.org/doi/abs/10.1137/1.9781611977073.1},
}






@InBook{Faour,
  author    = {Salwa Faour and Mohsen Ghaffari and Christoph Grunau and Fabian Kuhn and Václav Rozhoň},
  pages     = {4409-4447},
  title     = {Local Distributed Rounding: Generalized to MIS, Matching, Set Cover, and Beyond},
  year      = {2023},
  abstract  = {We develop a general deterministic distributed method for locally rounding fractional solutions of graph problems for which the analysis can be broken down into analyzing pairs of vertices. Roughly speaking, the method can transform fractional/probabilistic label assignments of the vertices into integral/deterministic label assignments for the vertices, while approximately preserving a potential function that is a linear combination of functions, each of which depends on at most two vertices (subject to some conditions usually satisfied in pairwise analyses). The method unifies and significantly generalizes prior work on deterministic local rounding techniques [Ghaffari, Kuhn FOCS'21; Harris FOCS'19; Fischer, Ghaffari, Kuhn FOCS'17; Fischer DISC'17] to obtain polylogarithmic-time deterministic distributed solutions for combinatorial graph problems. Our general rounding result enables us to locally and efficiently derandomize a range of distributed algorithms for local graph problems, including maximal independent set (MIS), maximum-weight independent set approximation, and minimum-cost set cover approximation. As highlights, we in particular obtain the following results. • We obtain a deterministic O(log2 Δ · log n)-round algorithm for computing an MIS in the LOCAL model and an almost as efficient O(log2 Δ · log log Δ · log n)-round deterministic MIS algorithm in the CONGEST model. As a result, the best known deterministic distributed time complexity of the four most widely studied distributed symmetry breaking problems (MIS, maximal matching, (Δ + 1)-vertex coloring, and (2Δ − 1)-edge coloring) is now O(log2 Δ · log n). Our new MIS algorithm is also the first direct polylogarithmic-time deterministic distributed MIS algorithm, which is not based on network decomposition. • We obtain efficient deterministic distributed algorithms for rounding fractional solutions for maximum (weighted) independent set and minimum (weighted) set cover. We in particular give a deterministic O(log2 Δ + log* n)-round algorithms for computing an independent set of size (1/2 — ε) · n/ degavg and we give deterministic O (log2 (ΔW) + log* n)-round algorithms for computing a (1 — ε)/Δ-approximation of maximum weight independent set, and for computing a (1 — ε)/r-approximation of maximum weight matching in hypergraphs of rank r. For minimum set cover instances with sets of size at most s and where each element is contained in at most t sets, we show that an O(log s)-approximation can be computed in time O(log s · log2 t + log* n). * The full version of the paper can be accessed at https://arxiv.org/abs/2209.11651},
  booktitle = {Proceedings of the 2023 Annual ACM-SIAM Symposium on Discrete Algorithms (SODA)},
  doi       = {10.1137/1.9781611977554.ch168},
  eprint    = {https://epubs.siam.org/doi/pdf/10.1137/1.9781611977554.ch168},
  url       = {https://epubs.siam.org/doi/abs/10.1137/1.9781611977554.ch168},
}






@InBook{Beaglehole,
  author    = {Daniel Beaglehole and Max Hopkins and Daniel Kane and Sihan Liu and Shachar Lovett},
  pages     = {3817-3855},
  title     = {Sampling Equilibria: Fast No-Regret Learning in Structured Games},
  year      = {2023},
  abstract  = {Learning and equilibrium computation in games are fundamental problems across computer science and economics, with applications ranging from politics to machine learning. Much of the work in this area revolves around a simple algorithm termed randomized weighted majority (RWM), also known as “Hedge” or “Multiplicative Weights Update,” which is well known to achieve statistically optimal rates in adversarial settings (Littlestone and Warmuth '94, Freund and Schapire '99). Unfortunately, RWM comes with an inherent computational barrier: it requires maintaining and sampling from a distribution over all possible actions. In typical settings of interest the action space is exponentially large, seemingly rendering RWM useless in practice. In this work, we refute this notion for a broad variety of structured games, showing it is possible to efficiently (approximately) sample the action space in RWM in polylogarithmic time. This gives the first efficient no-regret algorithms for problems such as the (discrete) Colonel Blotto game, matroid congestion, matroid security, and basic dueling games. As an immediate corollary, we give a polylogarithmic time meta-algorithm to compute approximate Nash Equilibria for these games that is exponentially faster than prior methods in several important settings. Further, our algorithm is the first to efficiently compute equilibria for more involved variants of these games with general sums, more than two players, and, for Colonel Blotto, multiple resource types. Our results also greatly generalize earlier work on efficient RWM-based techniques for exponential strategy sets from (Cesa-Bianchi and Lugosi '09).},
  booktitle = {Proceedings of the 2023 Annual ACM-SIAM Symposium on Discrete Algorithms (SODA)},
  doi       = {10.1137/1.9781611977554.ch149},
  eprint    = {https://epubs.siam.org/doi/pdf/10.1137/1.9781611977554.ch149},
  url       = {https://epubs.siam.org/doi/abs/10.1137/1.9781611977554.ch149},
}






@InBook{Im,
  author    = {Sungjin Im and Shi Li},
  pages     = {2917-2946},
  title     = {Improved Approximations for Unrelated Machine Scheduling},
  year      = {2023},
  abstract  = {We revisit two well-studied scheduling problems in the unrelated machines setting where each job can have a different processing time on each machine. For minimizing total weighted completion time we give a 1.45-approximation, which improves upon the previous 1.488-approximation [Im and Shadloo SODA 2020]. The key technical ingredient in this improvement lies in a new rounding scheme that gives strong negative correlation with less restrictions. For minimizing Lk-norms of machine loads, inspired by [Kalaitzis et al. SODA 2017], we give better approximation algorithms. In particular we give a -approximation for the L2-norm which improves upon the former -approximations due to [Azar-Epstein STOC 2005] and [Kumar et al. JACM 2009].},
  booktitle = {Proceedings of the 2023 Annual ACM-SIAM Symposium on Discrete Algorithms (SODA)},
  doi       = {10.1137/1.9781611977554.ch111},
  eprint    = {https://epubs.siam.org/doi/pdf/10.1137/1.9781611977554.ch111},
  url       = {https://epubs.siam.org/doi/abs/10.1137/1.9781611977554.ch111},
}






@InBook{Liu,
  author    = {Allen Liu and Ankur Moitra},
  pages     = {3471-3512},
  title     = {Robust Voting Rules from Algorithmic Robust Statistics},
  year      = {2023},
  abstract  = {Maximum likelihood estimation furnishes powerful insights into voting theory, and the design of voting rules. However the MLE can usually be badly corrupted by a single outlying sample. This means that a single voter or a group of colluding voters can vote strategically and drastically affect the outcome. Motivated by recent progress in algorithmic robust statistics, we revisit the fundamental problem of estimating the central ranking in a Mallows model, but ask for an estimator that is provably robust, unlike the MLE. Our main result is an efficiently computable estimator that achieves nearly optimal robustness guarantees. In particular the robustness guarantees are dimension-independent in the sense that our overall accuracy does not depend on the number of alternatives being ranked. As an immediate consequence, we show that while the landmark Gibbard-Satterthwaite theorem tells us a strong impossibility result about designing strategy-proof voting rules, there are quantitatively strong ways to protect against large coalitions if we assume that the remaining voters are honest and their preferences are sampled from a Mallows model. Our work also makes technical contributions to algorithmic robust statistics by designing new spectral filtering techniques that can exploit the intricate combinatorial dependencies in the Mallows model. * The full version of the paper can be accessed at https://arxiv.org/abs/2112.06380},
  booktitle = {Proceedings of the 2023 Annual ACM-SIAM Symposium on Discrete Algorithms (SODA)},
  doi       = {10.1137/1.9781611977554.ch133},
  eprint    = {https://epubs.siam.org/doi/pdf/10.1137/1.9781611977554.ch133},
  url       = {https://epubs.siam.org/doi/abs/10.1137/1.9781611977554.ch133},
}






@InBook{Kong,
  author    = {Fang Kong and Shuai Li},
  pages     = {1512-1522},
  title     = {Player-optimal Stable Regret for Bandit Learning in Matching Markets},
  year      = {2023},
  abstract  = {The problem of matching markets has been studied for a long time in the literature due to its wide range of applications. Finding a stable matching is a common equilibrium objective in this problem. Since market participants are usually uncertain of their preferences, a rich line of recent works study the online setting where one-side participants (players) learn their unknown preferences from iterative interactions with the other side (arms). Most previous works in this line are only able to derive theoretical guarantees for player-pessimal stable regret, which is defined compared with the players' least-preferred stable matching. However, under the pessimal stable matching, players only obtain the least reward among all stable matchings. To maximize players' profits, player-optimal stable matching would be the most desirable. Though Basu et al. [2021] successfully bring an upper bound for player-optimal stable regret, their result can be exponentially large if players' preference gap is small. Whether a polynomial guarantee for this regret exists is a significant but still open problem. In this work, we provide a new algorithm named explore-then-Gale-Shapley (ETGS) and show that the optimal stable regret of each player can be upper bounded by O(K log T/Δ2) where K is the number of arms, T is the horizon and Δ is the players' minimum preference gap. This result significantly improves previous works which either have a weaker player-pessimal stable matching objective or apply only to markets with special assumptions. When the preferences of participants satisfy some special conditions, our regret upper bound also matches the previously derived lower bound.},
  booktitle = {Proceedings of the 2023 Annual ACM-SIAM Symposium on Discrete Algorithms (SODA)},
  doi       = {10.1137/1.9781611977554.ch55},
  eprint    = {https://epubs.siam.org/doi/pdf/10.1137/1.9781611977554.ch55},
  url       = {https://epubs.siam.org/doi/abs/10.1137/1.9781611977554.ch55},
}






@InBook{Ahmadian,
  author    = {Sara Ahmadian and Hossein Esfandiari and Vahab Mirrokni and Binghui Peng},
  pages     = {20-34},
  title     = {Robust Load Balancing with Machine Learned Advice},
  year      = {2022},
  abstract  = {Motivated by the exploding growth of web-based services and the importance of efficiently managing the computational resources of such systems, we introduce and study a theoretical model for load balancing of very large databases such as commercial search engines. Our model is a more realistic version of the well-received balls-into-bins model with an additional constraint that limits the number of servers that carry each piece of the data. This additional constraint is necessary when, on one hand, the data is so large that we can not copy the whole data on each server. On the other hand, the query response time is so limited that we can not ignore the fact that the number of queries for each piece of the data changes over time, and hence we can not simply split the data over different machines In this paper, we develop an almost optimal load balancing algorithm that works given an estimate of the load of each piece of the data. Our algorithm is almost perfectly robust to wrong estimates, to the extent that even when all of the loads are adversarially chosen the performance of our algorithm is 1–1/e, which is provably optimal. Along the way, we develop various techniques for analyzing the balls-into-bins process under certain correlations and build a novel connection with the multiplicative weights update scheme.},
  booktitle = {Proceedings of the 2022 Annual ACM-SIAM Symposium on Discrete Algorithms (SODA)},
  doi       = {10.1137/1.9781611977073.2},
  eprint    = {https://epubs.siam.org/doi/pdf/10.1137/1.9781611977073.2},
  url       = {https://epubs.siam.org/doi/abs/10.1137/1.9781611977073.2},
}






@InBook{Kaplan,
  author    = {Haim Kaplan and David Naori and Danny Raz},
  pages     = {1247-1272},
  title     = {Online Weighted Matching with a Sample},
  year      = {2022},
  abstract  = {We study the greedy-based online algorithm for edge-weighted matching with (one-sided) vertex arrivals in bipartite graphs, and edge arrivals in general graphs. This algorithm was first studied more than a decade ago by Korula and Pál for the bipartite case in the random-order model. While the weighted bipartite matching problem is solved in the random-order model, this is not the case in recent and exciting online models in which the online player is provided with a sample, and the arrival order is adversarial. The greedy-based algorithm is arguably the most natural and practical algorithm to be applied in these models. Despite its simplicity and appeal, and despite being studied in multiple works, the greedy-based algorithm was not fully understood in any of the studied online models, and its actual performance remained an open question for more than a decade. We provide a thorough analysis of the greedy-based algorithm in several online models. For vertex arrivals in bipartite graphs, we characterize the exact competitive-ratio of this algorithm in the random-order model, for any arrival order of the vertices subsequent to the sampling phase (adversarial and random orders in particular). We use it to derive tight analysis in the recent adversarial-order model with a sample (AOS model) for any sample size, providing the first result in this model beyond the simple secretary problem. Then, we generalize and strengthen the black box method of converting results in the random-order model to single-sample prophet inequalities, and use it to derive the state-of-the-art single-sample prophet inequality for the problem. Finally, we use our new techniques to analyze the greedy-based algorithm for edge arrivals in general graphs and derive results in all the mentioned online models. In this case as well, we improve upon the state-of-the-art single-sample prophet inequality.},
  booktitle = {Proceedings of the 2022 Annual ACM-SIAM Symposium on Discrete Algorithms (SODA)},
  doi       = {10.1137/1.9781611977073.52},
  eprint    = {https://epubs.siam.org/doi/pdf/10.1137/1.9781611977073.52},
  url       = {https://epubs.siam.org/doi/abs/10.1137/1.9781611977073.52},
}






@InBook{Deng,
  author    = {Shichuan Deng and Jian Li and Yuval Rabani},
  pages     = {2898-2916},
  title     = {Generalized Unrelated Machine Scheduling Problem},
  year      = {2023},
  abstract  = {We study the generalized load-balancing (GLB) problem, where we are given n jobs, each of which needs to be assigned to one of m unrelated machines with processing times {pij}. Under a job assignment σ, the load of each machine i is Ψi(pi[σ]) where ψi: ℝn → ℝ≥0 is a symmetric monotone norm and pi[σ] is the n- dimensional vector {pij · 𝕀 [σ(j) = i]}j∈[n]. Our goal is to minimize the generalized makespan ø(load(σ)), where φ : ℝm → ℝ≥0 is another symmetric monotone norm and load(σ) is the m-dimensional machine load vector. This problem significantly generalizes many classic optimization problems, e.g., makespan minimization, set cover, minimum-norm load-balancing, etc. We also study the special case of identical machine scheduling, i.e., Pij = pj for all machine i. Our main result is a polynomial time randomized algorithm that achieves an approximation factor of O(log n), matching the lower bound of set cover (which is special case of GLB) up to constant factor. We achieve this by rounding a novel configuration LP relaxation with exponential number of variables. To approximately solve the configuration LP, we design an approximate separation oracle for its dual program. In particular, the separation oracle can be reduced to the norm minimization with a linear constraint (NormLin) problem and we devise a polynomial time approximation scheme (PTAS) for it, which may be of independent interest. We also obtain constant factor approximation algorithms for some special cases.},
  booktitle = {Proceedings of the 2023 Annual ACM-SIAM Symposium on Discrete Algorithms (SODA)},
  doi       = {10.1137/1.9781611977554.ch110},
  eprint    = {https://epubs.siam.org/doi/pdf/10.1137/1.9781611977554.ch110},
  url       = {https://epubs.siam.org/doi/abs/10.1137/1.9781611977554.ch110},
}






@InBook{Boodaghians,
  author    = {Shant Boodaghians and Bhaskar Ray Chaudhury and Ruta Mehta},
  pages     = {2285-2302},
  title     = {Polynomial Time Algorithms to Find an Approximate Competitive Equilibrium for Chores},
  year      = {2022},
  abstract  = {Competitive equilibrium with equal income (CEEI) is considered one of the best mechanisms to allocate a set of items among agents fairly and efficiently. In this paper, we study the computation of CEEI when items are chores that are disliked (negatively valued) by agents, under 1-homogeneous and concave utility functions which includes linear functions as a subcase. It is well-known that, even with linear utilities, the set of CEEI may be non-convex and disconnected, and the problem is PPAD-hard in the more general exchange model. In contrast to these negative results, we design a FPTAS: A polynomial-time algorithm to compute ∊-approximate CEEI where the running-time depends polynomially on . Our algorithm relies on the recent characterization due to Bogomolnaia et al. (2017) of the CEEI set as exactly the KKT points of a non-convex minimization problem that have all coordinates non-zero. Due to this non-zero constraint, naïve gradient-based methods fail to find the desired local minima as they are attracted towards zero. We develop an exterior-point method that alternates between guessing non-zero KKT points and maximizing the objective along supporting hyperplanes at these points. We show that this procedure must converge quickly to an approximate KKT point which then can be mapped to an approximate CEEI; this exterior point method may be of independent interest. When utility functions are linear, we give explicit procedures for finding the exact iterates, and as a result show that a stronger form of approximate CEEI can be found in polynomial time. Finally, we note that our algorithm extends to the setting of un-equal incomes (CE), and to mixed manna with linear utilities where each agent may like (positively value) some items and dislike (negatively value) others.},
  booktitle = {Proceedings of the 2022 Annual ACM-SIAM Symposium on Discrete Algorithms (SODA)},
  doi       = {10.1137/1.9781611977073.92},
  eprint    = {https://epubs.siam.org/doi/pdf/10.1137/1.9781611977073.92},
  url       = {https://epubs.siam.org/doi/abs/10.1137/1.9781611977073.92},
}






@Article{Branzei2022,
  author   = {Br\^{a}nzei, Simina and Gkatzelis, Vasilis and Mehta, Ruta},
  journal  = {Operations Research},
  title    = {Nash Social Welfare Approximation for Strategic Agents},
  year     = {2022},
  number   = {1},
  pages    = {402-415},
  volume   = {70},
  abstract = {We study the problem of allocating divisible resources to agents with different preferences. We analyze a market game known as Trading Post, first considered by Shapley and Shubik, where each agent gets a budget of virtual currency to bid on goods: after bids are placed, goods are allocated to players in proportion to their bids. In this setting, the agents choose their bids strategically, aiming to maximize their utility, and this gives rise to a game. We study the equilibrium allocations of this game, measuring the quality of an allocation via the Nash social welfare, the geometric mean of utilities (a measure of aggregate welfare that respects individual needs). We show that any Nash equilibrium of Trading Post approximates the optimal Nash welfare within a factor of two for all concave valuations, and the mechanism is essentially optimal for Leontief valuations.},
  doi      = {10.1287/opre.2020.2056},
  eprint   = {https://doi.org/10.1287/opre.2020.2056},
  url      = {https://doi.org/10.1287/opre.2020.2056},
}

@Article{Oluwasuji2019,
  author   = {Oluwasuji, Olabambo Ifeoluwa and Malik, Obaid and Zhang, Jie and Ramchurn, Sarvapali Dyanand},
  journal  = {Autonomous Agents and Multi-Agent Systems},
  title    = {Solving the fair electric load shedding problem in developing countries},
  year     = {2019},
  issn     = {1573-7454},
  number   = {1},
  pages    = {12},
  volume   = {34},
  abstract = {Often because of limitations in generation capacity of power stations, many developing countries frequently resort to disconnecting large parts of the power grid from supply, a process termed load shedding. This leaves households in disconnected parts without electricity, causing them inconvenience and discomfort. Without fairness being taken into due consideration during load shedding, some households may suffer more than others. In this paper, we solve the fair load shedding problem (FLSP) by creating solutions which connect households to supply based on some fairness criteria (i.e., to fairly connect homes to supply in terms of duration, their electricity needs, and their demand), which we model as their utilities. First, we briefly describe some state-of-art household-level load shedding heuristics which meet the first criteria. Second, we model the FLSP as a resource allocation problem, which we formulate into two Mixed Integer Programming (MIP) problems based on the Multiple Knapsack Problem. In so doing, we use the utilitarian, egalitarian and envy-freeness social welfare metrics to develop objectives and constraints that ensure our FLSP solutions results in fair allocations that consider the utilities of agents. Then, we solve the FLSP and show that our MIP models maximize the groupwise and individual utilities of agents, and minimize the differences between their pairwise utilities under a number of experiments. When taken together, our endeavour establishes a set of benchmarks for fair load shedding schemes, and provide insights for designing fair allocation solutions for other scarce resources.},
  doi      = {10.1007/s10458-019-09428-8},
  refid    = {Oluwasuji2019},
  url      = {https://doi.org/10.1007/s10458-019-09428-8},
}

@InProceedings{Ackermann2006,
  author    = {Ackermann, Heiner and Roglin, Heiko and Vocking, Berthold},
  booktitle = {2006 47th Annual IEEE Symposium on Foundations of Computer Science (FOCS'06)},
  title     = {On the Impact of Combinatorial Structure on Congestion Games},
  year      = {2006},
  pages     = {613-622},
  doi       = {10.1109/FOCS.2006.55},
  keywords  = {Convergence;Polynomials;Nash equilibrium;Delay;Resource management;Search problems;Computer science;Time factors;Sufficient conditions;Costs},
}

@InProceedings{Hao2024,
  author    = {Hao, Bainian and Michini, Carla},
  booktitle = {Algorithmic Game Theory},
  title     = {Price of Anarchy in Paving Matroid Congestion Games},
  year      = {2024},
  address   = {Cham},
  editor    = {Sch{\"a}fer, Guido and Ventre, Carmine},
  pages     = {353--370},
  publisher = {Springer Nature Switzerland},
  abstract  = {Congestion games allow to model competitive resource sharing in various distributed systems. Pure Nash equilibria, that are stable outcomes of a game, could be far from being socially optimal. Our goal is to identify combinatorial structures that limit the inefficiency of equilibria. This question has been mainly investigated for congestion games defined over networks. Instead, we focus on symmetric matroid congestion games, where the strategies of every player are the bases of a given matroid. We derive new upper bounds on the Price of Anarchy (PoA) of congestion games defined over k-uniform matroids and paving matroids with delay functions in class {\$}{\$}{\backslash}mathcal {\{}D{\}}{\$}{\$}D. For both affine and polynomial delay functions, our bounds indicate that the inefficiency of pure Nash equilibria is limited by these combinatorial structures.},
  isbn      = {978-3-031-71033-9},
}

@Article{Balcan2013a,
  author     = {Balcan, Maria-Florina and Blum, Avrim and Mansour, Yishay},
  journal    = {ACM Trans. Econ. Comput.},
  title      = {The Price of Uncertainty},
  year       = {2013},
  issn       = {2167-8375},
  month      = sep,
  number     = {3},
  volume     = {1},
  abstract   = {In this work, we study the degree to which small fluctuations in costs in well-studied potential games can impact the result of natural best-response and improved-response dynamics. We call this the Price of Uncertainty and study it in a wide variety of potential games including fair cost-sharing games, set-cover games, routing games, and job-scheduling games. We show that in certain cases, even extremely small fluctuations can have the ability to cause these dynamics to spin out of control and move to states of much higher social cost, whereas in other cases these dynamics are much more stable even to large degrees of fluctuation.We also consider the resilience of these dynamics to a small number of Byzantine players about which no assumptions are made. We show again a contrast between different games. In certain cases (e.g., fair cost-sharing, set-cover, job-scheduling) even a single Byzantine player can cause best-response dynamics to transition from low-cost states to states of substantially higher cost, whereas in others (e.g., the class of β-nice games, which includes routing, market-sharing and many others) these dynamics are much more resilient.Overall, our work can be viewed as analyzing the inherent resilience or safety of games to different kinds of imperfections in player behavior, player information, or in modeling assumptions made.},
  address    = {New York, NY, USA},
  articleno  = {15},
  doi        = {10.1145/2509413.2509415},
  issue_date = {September 2013},
  keywords   = {Game theory, best-response dynamics, potential games, quality of equilibria, social cost, uncertainty},
  numpages   = {29},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/2509413.2509415},
}

@Article{Piliouras2016,
  author     = {Piliouras, Georgios and Nikolova, Evdokia and Shamma, Jeff S.},
  journal    = {ACM Trans. Econ. Comput.},
  title      = {Risk Sensitivity of Price of Anarchy under Uncertainty},
  year       = {2016},
  issn       = {2167-8375},
  month      = oct,
  number     = {1},
  volume     = {5},
  abstract   = {In game theory, the price of anarchy framework studies efficiency loss in decentralized environments. Optimization and decision theory, on the other hand, explore tradeoffs between optimality and robustness in the case of single-agent decision making under uncertainty. What happens when we combine both approaches?We examine connections between the efficiency loss due to decentralization and the efficiency loss due to uncertainty and establish tight performance guarantees for distributed systems in uncertain environments. We present applications based on novel variants of atomic congestion games with uncertain costs, for which we provide tight performance bounds under a wide range of risk attitudes. Our results establish that the individual’s attitude toward uncertainty has a critical effect on system performance and therefore should be a subject of close and systematic investigation.},
  address    = {New York, NY, USA},
  articleno  = {5},
  doi        = {10.1145/2930956},
  issue_date = {February 2017},
  keywords   = {stochastic optimization, congestion games, Robust optimization},
  numpages   = {27},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/2930956},
}






@Article{Gravin2023,
  author   = {Gravin, Nick and Wang, Hongao},
  journal  = {Mathematics of Operations Research},
  title    = {Prophet Inequality for Bipartite Matching: Merits of Being Simple and Nonadaptive},
  year     = {2023},
  number   = {1},
  pages    = {38-52},
  volume   = {48},
  abstract = {We consider the Bayesian online selection problem of a matching in bipartite graphs, that is, the weighted online matching problem where the edges arrive online and edge weights are generated from a known distribution. This setting corresponds to the intersection of two matroids in the work of Kleinberg and Weinberg [40] and Feldman et al. [27]. We study a simple class of nonadaptive policies that we call vertex-additive policies. A vertex-additive policy assigns static prices to every vertex in the graph and accepts only those edges whose weight exceeds the sum of the prices on the edge endpoints. We show that there exists a vertex-additive policy with the expected payoff of at least one-third of the prophet’s payoff and present a gradient descent algorithm that quickly converges to the desired vector of vertex prices. Our results improve on the adaptive online policies of Kleinberg and Weinberg and Feldman et al. for the intersection of two matroids in two ways: our policy is nonadaptive and has a better approximation guarantee of 3 instead of the previous guarantees of 5.82 in Kleinberg and Weinberg and 5.43 in Feldman et al. We give a complementary lower bound of 2.25 for any online algorithm in the bipartite matching setting.Funding: This work was supported by Fundamental Research Funds of the Central Universities in China, a Science and Technology Innovation 2030 major project [“New Generation of Artificial Intelligence,” Project 2018AAA0100903], the Shanghai Municipal Education Commission Innovation Program, and the Program for Innovative Research Team of the Shanghai University of Finance and Economics (IRTSHUFE).},
  doi      = {10.1287/moor.2022.1251},
  eprint   = {https://doi.org/10.1287/moor.2022.1251},
  url      = {https://doi.org/10.1287/moor.2022.1251},
}

@Article{Amano2025,
  author    = {Amano, Yuki and Igarashi, Ayumi and Kawase, Yasushi and Makino, Kazuhisa and Ono, Hirotaka},
  journal   = {ACM Trans. Econ. Comput.},
  title     = {Fair Ride Allocation on a Line},
  year      = {2025},
  issn      = {2167-8375},
  month     = jan,
  note      = {Just Accepted},
  abstract  = {The airport problem is a classical and well-known model of fair cost-sharing for a single facility among multiple agents. This paper extends it to a more general setting involving multiple facilities. Specifically, in our model, each agent selects a facility and shares the cost with the other agents using the same facility. This scenario frequently occurs in sharing economies, such as sharing subscription costs for a multi-user license or taxi fares among customers traveling to potentially different destinations along a route. Our model can be viewed as a coalition formation game with size constraints, based on the fair cost-sharing of the airport problem. We refer to our model as a fair ride allocation on a line. We incorporate Nash stability and envy-freeness as criteria for solution concepts in our setting. We show that if a feasible allocation exists, a Nash stable feasible allocation that minimizes the social cost of agents exists and can be computed efficiently. Regarding envy-freeness, we provide several structural properties of envy-free allocations. Based on these properties, we design efficient algorithms for finding an envy-free allocation when either (1) the number of facilities, (2) the number of agent types, or (3) the capacity of facilities, is small. Moreover, we show that a consecutive envy-free allocation can be computed in polynomial time. On the negative front, we show NP-completeness of determining the existence of an allocation under two relaxed envy-free concepts.},
  address   = {New York, NY, USA},
  doi       = {10.1145/3708491},
  groups    = {ideas},
  publisher = {Association for Computing Machinery},
  url       = {https://doi.org/10.1145/3708491},
}

@Article{Chakraborty2024,
  author     = {Chakraborty, Mithun and Segal-Halevi, Erel and Suksompong, Warut},
  journal    = {ACM Trans. Econ. Comput.},
  title      = {Weighted Fairness Notions for Indivisible Items Revisited},
  year       = {2024},
  issn       = {2167-8375},
  month      = sep,
  number     = {3},
  volume     = {12},
  abstract   = {We revisit the setting of fairly allocating indivisible items when agents have different weights representing their entitlements. First, we propose a parameterized family of relaxations for weighted envy-freeness and the same for weighted proportionality; the parameters indicate whether smaller-weight or larger-weight agents are given a higher priority. We show that each notion in these families can always be satisfied, but any two cannot necessarily be fulfilled simultaneously. We then introduce an intuitive weighted generalization of maximin share fairness and establish the optimal approximation of it that can be guaranteed. Furthermore, we characterize the implication relations between the various weighted fairness notions introduced in this and prior work, and relate them to the lower and upper quota axioms from apportionment.},
  address    = {New York, NY, USA},
  articleno  = {9},
  doi        = {10.1145/3665799},
  issue_date = {September 2024},
  keywords   = {Unequal entitlements, fair division, indivisible items, resource allocation},
  numpages   = {45},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/3665799},
}

@Article{Hao2024a,
  author     = {Hao, Bainian and Michini, Carla},
  journal    = {ACM Trans. Econ. Comput.},
  title      = {Inefficiency of pure Nash equilibria in network congestion games: the impact of symmetry and network structure},
  year       = {2024},
  issn       = {2167-8375},
  month      = sep,
  number     = {3},
  volume     = {12},
  abstract   = {We study the inefficiency of pure Nash equili bria in symmetric unweighted network congestion games. We first explore the impact of symmetry on the worst-case PoA of network congestion games. For polynomial delay functions with highest degree p, we construct a family of symmetric congestion games over arbitrary networks which achieves the same worst-case PoA of asymmetric network congestion games. Next, we explore the impact of network structure within the class of symmetric network congestion games. For delay functions in class 𝒟, we introduce a quantity y(𝒟) and we show that the PoA is at most y(𝒟) in games defined over series-parallel networks. Thus, for polynomial delays with highest degree p, the PoA cannot exceed 2p+1 - 1, which is significantly smaller than the worst-case PoA in games defined over arbitrary networks. Moreover, we prove that the worst-case PoA quickly degrades from sub-linear to exponential when relaxing the network topology form extension-parallel to series-parallel.Finally, we consider measuring the social cost as the maximum players’ cost. For polynomial delays of maximum degree p we show that the worst-case PoA is significantly smaller than that of general symmetric congestion games, but dramatically larger than that of games defined over extension-parallel networks.},
  address    = {New York, NY, USA},
  articleno  = {8},
  doi        = {10.1145/3665590},
  issue_date = {September 2024},
  keywords   = {Congestion games, series-parallel networks, price of anarchy},
  numpages   = {30},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/3665590},
}

@Article{Hosseini2024,
  author   = {Hadi Hosseini and Zhiyi Huang and Ayumi Igarashi and Nisarg Shah},
  journal  = {Artificial Intelligence},
  title    = {Class fairness in online matching},
  year     = {2024},
  issn     = {0004-3702},
  pages    = {104177},
  volume   = {335},
  abstract = {We initiate the study of fairness among classes of agents in online bipartite matching where there is a given set of offline vertices (aka agents) and another set of vertices (aka items) that arrive online and must be matched irrevocably upon arrival. In this setting, agents are partitioned into classes and the matching is required to be fair with respect to the classes. We adapt popular fairness notions (e.g. envy-freeness, proportionality, and maximin share) and their relaxations to this setting and study deterministic algorithms for matching indivisible items (leading to integral matchings) and for matching divisible items (leading to fractional matchings). For matching indivisible items, we propose an adaptive-priority-based algorithm, Match-and-Shift, prove that it achieves 12-approximation of both class envy-freeness up to one item and class maximin share fairness, and show that each guarantee is tight. For matching divisible items, we design a water-filling-based algorithm, Equal-Filling, that achieves (1−1e)-approximation of class envy-freeness and class proportionality; we prove 1−1e to be tight for class proportionality and establish a 34 upper bound on class envy-freeness. Finally, we discuss several challenges in designing randomized algorithms that achieve reasonable fairness approximation ratios. Nonetheless, we build upon Equal-Filling to design a randomized algorithm for matching indivisible items, Equal-Filling-OCS, which achieves 0.593-approximation of class proportionality.},
  doi      = {https://doi.org/10.1016/j.artint.2024.104177},
  keywords = {Fair division, Online algorithms, Social welfare, Matching},
  url      = {https://www.sciencedirect.com/science/article/pii/S0004370224001139},
}

@Article{Aleksandrov2025,
  author   = {Martin Aleksandrov},
  journal  = {Transportation Research Procedia},
  title    = {Fairness and Efficiency in Social Vehicle Routing Problems},
  year     = {2025},
  issn     = {2352-1465},
  note     = {World Conference on Transport Research - WCTR 2023 Montreal 17-21 July 2023},
  pages    = {1994-2013},
  volume   = {82},
  abstract = {We define Social Vehicle Routing Problems (SVRPs), where preferences of drivers and vehicles, feasibility constraints between vehicles and requests, and network metrics, inform the management of the feet. We propose new algorithms for SVRPs, first returning a feasible matching between drivers and customers and then an optimizing feasible plan for routing the vehicles through their matched locations. We give matching algorithms for achieving fairness (i.e. FEF1, FEQX, FEFX) for drivers, efficiency (i.e. FSWmax) for drivers, and fairness and efficiency (i.e. FSWmin) for customers. Finally, we also give fixed-parameter tractable routing algorithms for fleet fairness (i.e. maxTRAVEL) and fleet efficiency (i.e. totTRAVEL).},
  doi      = {https://doi.org/10.1016/j.trpro.2024.12.168},
  keywords = {Vehicle Routing Problems, Computational Social Choice, Fairness, Efficiency},
  url      = {https://www.sciencedirect.com/science/article/pii/S2352146524004678},
}

@InProceedings{Kawase2022,
  author    = {Kawase, Yasushi and Sumita, Hanna},
  booktitle = {Algorithmic Game Theory},
  title     = {Online Max-min Fair Allocation},
  year      = {2022},
  address   = {Cham},
  editor    = {Kanellopoulos, Panagiotis and Kyropoulou, Maria and Voudouris, Alexandros},
  pages     = {526--543},
  publisher = {Springer International Publishing},
  abstract  = {We study an online version of the max-min fair allocation problem for indivisible items. In this problem, items arrive one by one, and each item must be allocated irrevocably on arrival to one of n agents, who have additive valuations for the items. Our goal is to maximize the egalitarian social welfare, which is the minimum happiness among the agents. In research on the topic of online allocation, this is a fundamental and natural problem. Our main result is to reveal the asymptotic competitive ratios of the problem for both the adversarial and i.i.d. input models. For the adversarial case, we design a polynomial-time deterministic algorithm that is asymptotically 1/n-competitive, and we show that this guarantee is optimal. Moreover, the algorithm satisfies proportionality in an asymptotic sense, that is, each agent receives a bundle of value at least nearly 1/n of the whole. For the case when the items are drawn from an unknown identical and independent distribution, we construct a simple polynomial-time deterministic algorithm that outputs a nearly optimal allocation. We analyze the strict competitive ratio and show almost tight bounds for the solution. We further mention some implications of our results on variants of the problem.},
  groups    = {ideas},
  isbn      = {978-3-031-15714-1},
}

@InProceedings{Aleksandrov2019,
  author    = {Aleksandrov, Martin and Walsh, Toby},
  booktitle = {PRICAI 2019: Trends in Artificial Intelligence},
  title     = {Strategy-Proofness, Envy-Freeness and Pareto Efficiency in Online Fair Division with Additive Utilities},
  year      = {2019},
  address   = {Cham},
  editor    = {Nayak, Abhaya C. and Sharma, Alok},
  pages     = {527--541},
  publisher = {Springer International Publishing},
  abstract  = {We consider fair division problems where indivisible items arrive one by one in an online fashion and are allocated immediately to agents who have additive utilities over these items. Many existing offline mechanisms do not work in this online setting. In addition, many existing axiomatic results often do not transfer from the offline to the online setting. For this reason, we propose here three new online mechanisms, as well as consider the axiomatic properties of three previously proposed online mechanisms. In this paper, we use these mechanisms and characterize classes of online mechanisms that are strategy-proof, and return envy-free and Pareto efficient allocations, as well as combinations of these properties. Finally, we identify an important impossibility result.},
  isbn      = {978-3-030-29908-8},
}

@InProceedings{Fikioris2024,
  author    = {Fikioris, Giannis and Agarwal, Rachit and Tardos, {\'E}va},
  booktitle = {Algorithmic Game Theory},
  title     = {Incentives in Dominant Resource Fair Allocation Under Dynamic Demands},
  year      = {2024},
  address   = {Cham},
  editor    = {Sch{\"a}fer, Guido and Ventre, Carmine},
  pages     = {108--125},
  publisher = {Springer Nature Switzerland},
  abstract  = {Every computer system performs resource allocation across system users. The defacto allocation policies used in most of these systems are max-min fairness for single resource settings and dominant resource fairness for multiple resources. These allocation schemes guarantee desirable properties like incentive compatibility, envy-freeness, and Pareto efficiency. Assuming that user demands are static (time-independent) the allocation is also fair. However, in modern real-world production systems, user demands are dynamic, that is, vary over time. As a result, there is now a fundamental mismatch between the resource allocation goals of computer systems and the properties enabled by classical resource allocation policies. This paper aims to bridge this mismatch. When demands are dynamic, instant-by-instant max-min fairness can be extremely unfair over a longer period of time, i.e., lead to unbalanced user allocations, as previous large allocations have no effect in the current time step. We consider a natural generalization of the classic algorithm for max-min fair allocation and dominant resource fairness for multiple resources when users have dynamic demands. This algorithm guarantees Pareto optimality while ensuring that resources allocated to users are as max-min fair as possible up to any time instant, given the allocation in previous periods. While this dynamic allocation scheme remains Pareto optimal and envy-free, unfortunately, it is not incentive compatible. We study the strength of the incentive to misreport; our results show that the possible increase in utility by misreporting demand is bounded and, since this misreporting can lead to a significant decrease in overall useful allocation, this suggests that it is not a useful strategy.},
  isbn      = {978-3-031-71033-9},
}

@Article{Kawase2023,
  author  = {Yasushi Kawase},
  journal = {Journal of the Operations Research Society of Japan},
  title   = {STOCHASTIC INPUT MODELS FOR ONLINE COMPUTING},
  year    = {2023},
  number  = {2},
  pages   = {95-111},
  volume  = {66},
  doi     = {10.15807/jorsj.66.95},
}

@Article{Igarashi2024,
  author   = {Ayumi Igarashi and Yasushi Kawase and Warut Suksompong and Hanna Sumita},
  journal  = {Games and Economic Behavior},
  title    = {Fair division with two-sided preferences},
  year     = {2024},
  issn     = {0899-8256},
  pages    = {268-287},
  volume   = {147},
  abstract = {We study a fair division setting in which participants are to be fairly distributed among teams, where not only do the teams have preferences over the participants as in the canonical fair division setting, but the participants also have preferences over the teams. We focus on guaranteeing envy-freeness up to one participant (EF1) for the teams together with a stability condition for both sides. We show that an allocation satisfying EF1, swap stability, and individual stability always exists and can be computed in polynomial time, even when teams may have positive or negative values for participants. When teams have nonnegative values for participants, we prove that an EF1 and Pareto optimal allocation exists and, if the valuations are binary, can be found in polynomial time. We also show that an EF1 and justified envy-free allocation does not necessarily exist, and deciding whether such an allocation exists is computationally difficult.},
  doi      = {https://doi.org/10.1016/j.geb.2024.07.008},
  url      = {https://www.sciencedirect.com/science/article/pii/S0899825624001027},
}

@Article{Imamura2024,
  author   = {Kenzo Imamura and Yasushi Kawase},
  journal  = {Games and Economic Behavior},
  title    = {Efficient matching under general constraints},
  year     = {2024},
  issn     = {0899-8256},
  pages    = {197-207},
  volume   = {145},
  abstract = {We study indivisible goods allocation problems under constraints and provide algorithms to check whether a given matching is Pareto efficient. We first show that the serial dictatorship algorithm can be used to check Pareto efficiency if the constraints are matroid. To prove this, we develop a generalized top trading cycles algorithm. Moreover, we show that the matroid structure is necessary for obtaining all Pareto efficient matchings by the serial dictatorship algorithm. Second, we provide an extension of the serial dictatorship algorithm to check Pareto efficiency under general constraints. As an application of our results to prioritized allocations, we discuss Pareto improving the deferred acceptance algorithm.},
  doi      = {https://doi.org/10.1016/j.geb.2024.03.013},
  keywords = {Matching with constraints, Efficient matching, Serial dictatorship, Top trading cycles, Matroid},
  url      = {https://www.sciencedirect.com/science/article/pii/S0899825624000447},
}

@InProceedings{Aleksandrov2020,
  author    = {Martin Aleksandrov and Toby Walsh},
  booktitle = {The Thirty-Fourth {AAAI} Conference on Artificial Intelligence, {AAAI} 2020, The Thirty-Second Innovative Applications of Artificial Intelligence Conference, {IAAI} 2020, The Tenth {AAAI} Symposium on Educational Advances in Artificial Intelligence, {EAAI} 2020, New York, NY, USA, February 7-12, 2020},
  title     = {Online Fair Division: {A} Survey},
  year      = {2020},
  pages     = {13557--13562},
  publisher = {{AAAI} Press},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  biburl    = {https://dblp.org/rec/conf/aaai/AleksandrovW20.bib},
  doi       = {10.1609/AAAI.V34I09.7081},
  groups    = {ideas},
}

@Article{Dickerson2021,
  author     = {Dickerson, John P. and Sankararaman, Karthik A. and Srinivasan, Aravind and Xu, Pan},
  journal    = {ACM Trans. Econ. Comput.},
  title      = {Allocation Problems in Ride-sharing Platforms: Online Matching with Offline Reusable Resources},
  year       = {2021},
  issn       = {2167-8375},
  month      = jun,
  number     = {3},
  volume     = {9},
  abstract   = {Bipartite-matching markets pair agents on one side of a market with agents, items, or contracts on the opposing side. Prior work addresses online bipartite-matching markets, where agents arrive over time and are dynamically matched to a known set of disposable resources. In this article, we propose a new model, Online Matching with (offline) Reusable Resources under Known Adversarial Distributions (OM-RR-KAD), in which resources on the offline side are reusable instead of disposable; that is, once matched, resources become available again at some point in the future. We show that our model is tractable by presenting an LP-based non-adaptive algorithm that achieves an online competitive ratio of ½-ϵ for any given constant ϵ > 0. We also show that no adaptive algorithm can achieve a ratio of ½ + o(1) based on the same benchmark LP. Through a data-driven analysis on a massive openly available dataset, we show our model is robust enough to capture the application of taxi dispatching services and ride-sharing systems. We also present heuristics that perform well in practice.},
  address    = {New York, NY, USA},
  articleno  = {13},
  doi        = {10.1145/3456756},
  issue_date = {September 2021},
  keywords   = {Online-matching, matching markets, randomized algorithms, rideshare},
  numpages   = {17},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/3456756},
}

@InProceedings{Cohen2024,
  author    = {Cohen, Saar and Agmon, Noa},
  booktitle = {Proceedings of the 23rd International Conference on Autonomous Agents and Multiagent Systems},
  title     = {Near-Optimal Online Resource Allocation in the Random-Order Model},
  year      = {2024},
  address   = {Richland, SC},
  pages     = {2219–2221},
  publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
  series    = {AAMAS '24},
  abstract  = {We study the problem of allocating either divisible or indivisible items (goods or chores) among a set of agents, where the items arrive online, one at a time. Each agent's non-negative value for an item is set by an adversary upon the item's arrival. Our focus is on a unifying algorithmic framework for finding online allocations that treats both fairness and economic efficiency. For this sake, we aim to optimize the generalized means of agents' received values, covering a spectrum of welfare functions including average utilitarian welfare and egalitarian welfare. In the traditional adversarial model, where items arrive in an arbitrary order, no algorithm can give a decent approximation to welfare in the worst case. To escape from this strong lower bound, we consider the random-order model, where items arrive in a uniformly random order. This model provides us with a major breakthrough: we devise algorithms that guarantee a nearly-optimal competitive ratio for certain welfare functions, if the welfare obtained by the optimal allocation is sufficiently large. We prove that our results are almost tight: if the optimal solution's welfare is strictly below a certain threshold, then no nearly-optimal algorithm exists, even in the random-order model.},
  isbn      = {9798400704864},
  keywords  = {generalized means, online fair division, random-order model, resource allocation},
  location  = {Auckland, New Zealand},
  numpages  = {3},
}

@Article{Esfandiari2018,
  author     = {Esfandiari, Hossein and Korula, Nitish and Mirrokni, Vahab},
  journal    = {ACM Trans. Econ. Comput.},
  title      = {Allocation with Traffic Spikes: Mixing Adversarial and Stochastic Models},
  year       = {2018},
  issn       = {2167-8375},
  month      = oct,
  number     = {3–4},
  volume     = {6},
  abstract   = {Motivated by Internet advertising applications, online allocation problems have been studied extensively in various adversarial and stochastic models. While the adversarial arrival models are too pessimistic, many of the stochastic (such as i.i.d. or random-order) arrival models do not realistically capture uncertainty in predictions. A significant cause for such uncertainty is the presence of unpredictable traffic spikes, often due to breaking news or similar events. To address this issue, a simultaneous approximation framework has been proposed to develop algorithms that work well both in the adversarial and stochastic models; however, this framework does not enable algorithms that make good use of partially accurate forecasts when making online decisions. In this article, we propose a robust online stochastic model that captures the nature of traffic spikes in online advertising. In our model, in addition to the stochastic input for which we have good forecasting, an unknown number of impressions arrive that are adversarially chosen. We design algorithms that combine a stochastic algorithm with an online algorithm that adaptively reacts to inaccurate predictions. We provide provable bounds for our new algorithms in this framework. We accompany our positive results with a set of hardness results showing that our algorithms are not far from optimal in this framework. As a byproduct of our results, we also present improved online algorithms for a slight variant of the simultaneous approximation framework.},
  address    = {New York, NY, USA},
  articleno  = {14},
  doi        = {10.1145/3105446},
  issue_date = {November 2018},
  keywords   = {Online matching, online advertisement, online budgeted allocation, traffic spikes},
  numpages   = {23},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/3105446},
}

@Comment{jabref-meta: databaseType:bibtex;}

@Comment{jabref-meta: grouping:
0 AllEntriesGroup:;
1 StaticGroup:ideas\;0\;1\;0x008000ff\;\;\;;
}
